"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[8040],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>u});var o=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,o)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,o,n=function(e,t){if(null==e)return{};var a,o,n={},r=Object.keys(e);for(o=0;o<r.length;o++)a=r[o],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)a=r[o],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var i=o.createContext({}),c=function(e){var t=o.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},d=function(e){var t=c(e.components);return o.createElement(i.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var a=e.components,n=e.mdxType,r=e.originalType,i=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),m=c(a),u=n,f=m["".concat(i,".").concat(u)]||m[u]||p[u]||r;return a?o.createElement(f,l(l({ref:t},d),{},{components:a})):o.createElement(f,l({ref:t},d))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var r=a.length,l=new Array(r);l[0]=m;var s={};for(var i in t)hasOwnProperty.call(t,i)&&(s[i]=t[i]);s.originalType=e,s.mdxType="string"==typeof e?e:n,l[1]=s;for(var c=2;c<r;c++)l[c]=a[c];return o.createElement.apply(null,l)}return o.createElement.apply(null,a)}m.displayName="MDXCreateElement"},9236:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>i,contentTitle:()=>l,default:()=>p,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var o=a(7462),n=(a(7294),a(3905));const r={},l="Metaflow on AWS",s={unversionedId:"v/r/metaflow-on-aws/metaflow-on-aws",id:"v/r/metaflow-on-aws/metaflow-on-aws",title:"Metaflow on AWS",description:"Traditionally, there has been a tension between local \\(e.g. on a laptop\\) and remote",source:"@site/docs/v/r/metaflow-on-aws/metaflow-on-aws.md",sourceDirName:"v/r/metaflow-on-aws",slug:"/v/r/metaflow-on-aws/",permalink:"/v/r/metaflow-on-aws/",draft:!1,editUrl:"https://github.dev/Netflix/metaflow-docs/blob/master/docs/v/r/metaflow-on-aws/metaflow-on-aws.md",tags:[],version:"current",frontMatter:{}},i={},c=[{value:"Amazon Web Services",id:"amazon-web-services",level:2},{value:"<strong>Datastore</strong>",id:"datastore",level:3},{value:"Compute",id:"compute",level:3},{value:"Metadata",id:"metadata",level:3},{value:"Notebooks",id:"notebooks",level:3},{value:"Scheduling",id:"scheduling",level:3},{value:"Using Metaflow with AWS",id:"using-metaflow-with-aws",level:2},{value:"Next Steps",id:"next-steps",level:2}],d={toc:c};function p(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,o.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"metaflow-on-aws"},"Metaflow on AWS"),(0,n.kt)("p",null,"Traditionally, there has been a tension between local ","(","e.g. on a laptop",")"," and remote\n","(","e.g. on a cluster or a cloud",")"," development and execution: Developing on a laptop is\nfast, whereas iterating with a remote cluster is slower. A laptop is a severely\nresource-constrained environment whereas a cluster can have virtually unlimited\nresources. Worse, simple local scripts may need to be translated to a new paradigm that\nis understood by a cluster."),(0,n.kt)("p",null,"Metaflow tries to combine the best of both worlds. Most importantly, we support the same\nidiomatic R scripts both locally and remotely. No changes in code or libraries needed.\nHowever, Metaflow doesn't try to abstract away the fact that code is executed remotely.\nWe believe that this is crucial in making troubleshooting easier."),(0,n.kt)("p",null,"Metaflow makes it easy to move back and forth between the local and remote modes of\nexecution. You can even use a hybrid of the two approaches in a single workflow. This\nmeans that you can develop and test your Metaflow code similarly to any local R script -\nsimply and easily. When you need to ",(0,n.kt)("a",{parentName:"p",href:"/v/r/metaflow/scaling"},"process larger amounts of\ndata"),", or you want to deploy your workflow to production, you\ncan do it with a single line of code or a single command."),(0,n.kt)("p",null,"When you set up a cloud-based object store as the datastore, Metaflow snapshots all data\nand code in the cloud automatically. This means that you can\n",(0,n.kt)("a",{parentName:"p",href:"/v/r/metaflow/client"},"inspect"),",\n",(0,n.kt)("a",{parentName:"p",href:"/v/r/metaflow/debugging#how-to-use-the-resume-command"},"resume"),", and restore any\nprevious Metaflow execution without having to worry that the fruits of your hard work\nget lost."),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},"Note that the R and Python versions of Metaflow work the same way on AWS since they\nboth share the same AWS integrations. The instructions here and in the ",(0,n.kt)("a",{parentName:"p",href:"https://outerbounds.com/docs/admin"},"Admin\nDocs")," apply to both versions.")),(0,n.kt)("h2",{id:"amazon-web-services"},"Amazon Web Services"),(0,n.kt)("p",null,"While technically Metaflow could work with any cloud provider, currently Metaflow\nsupports only ",(0,n.kt)("a",{parentName:"p",href:"https://aws.amazon.com"},"Amazon Web Services")," as the remote backend,\nthanks to Netflix's decade-long experience with AWS."),(0,n.kt)("p",null,"The following table summarizes the integration between Metaflow and AWS:"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:"left"},"Service"),(0,n.kt)("th",{parentName:"tr",align:"left"},"Local"),(0,n.kt)("th",{parentName:"tr",align:"left"},"AWS"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("strong",{parentName:"td"},"Datastore")),(0,n.kt)("td",{parentName:"tr",align:"left"},"Local Directory"),(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("a",{parentName:"td",href:"https://aws.amazon.com/s3/"},"Amazon S3"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("strong",{parentName:"td"},"Compute")),(0,n.kt)("td",{parentName:"tr",align:"left"},"Local Process"),(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("a",{parentName:"td",href:"https://aws.amazon.com/batch/"},"AWS Batch"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("strong",{parentName:"td"},"Metadata")),(0,n.kt)("td",{parentName:"tr",align:"left"},"Local Directory"),(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("a",{parentName:"td",href:"https://aws.amazon.com/fargate/"},"AWS Fargate")," + ",(0,n.kt)("a",{parentName:"td",href:"https://aws.amazon.com/rds"},"Amazon RDS"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("strong",{parentName:"td"},"Notebooks")),(0,n.kt)("td",{parentName:"tr",align:"left"},"Local Notebook"),(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("a",{parentName:"td",href:"https://aws.amazon.com/sagemaker/"},"Amazon Sagemaker Notebooks"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("strong",{parentName:"td"},"Scheduling")),(0,n.kt)("td",{parentName:"tr",align:"left"},"-"),(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("a",{parentName:"td",href:"https://aws.amazon.com/step-functions/"},"AWS Step Functions")," + ",(0,n.kt)("a",{parentName:"td",href:"https://aws.amazon.com/eventbridge/"},"Amazon EventBridge"))),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("strong",{parentName:"td"},"Large-scale ML")),(0,n.kt)("td",{parentName:"tr",align:"left"},"-"),(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("a",{parentName:"td",href:"https://aws.amazon.com/sagemaker/"},"Sagemaker Models"),"*")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:"left"},(0,n.kt)("strong",{parentName:"td"},"Hosting")),(0,n.kt)("td",{parentName:"tr",align:"left"},"-"),(0,n.kt)("td",{parentName:"tr",align:"left"},"*")))),(0,n.kt)("p",null,"(","*",")"," ",(0,n.kt)("a",{parentName:"p",href:"introduction/roadmap"},"available later")),(0,n.kt)("h3",{id:"datastore"},(0,n.kt)("strong",{parentName:"h3"},"Datastore")),(0,n.kt)("p",null,"Datastore is a centralized data repository for all the data that's leveraged by and\ngenerated by Metaflow flows. In the local mode, all data artifacts are stored in a local\ndirectory. Metaflow integrates with Amazon S3 for cloud-scale storage so that you can\nprocess and persist larger amounts of data easily."),(0,n.kt)("h3",{id:"compute"},"Compute"),(0,n.kt)("p",null,"Metaflow executes all steps in the flow as a separate local process in local mode. To\nrun larger workloads which require resources that might not be available on a laptop\n","(","think GPUs or 100s of GBs of RAM",")",", Metaflow integrates with AWS Batch to seamlessly\nrun every step of the flow as a ","(","or many",")"," separate AWS Batch job","(","s",")","."),(0,n.kt)("h3",{id:"metadata"},"Metadata"),(0,n.kt)("p",null,"Metaflow ships with a light-weight ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow-service"},"metaflow\nservice")," that provides a centralized place\nto keep track of all flow executions. This metadata service is not strictly needed.\nMetaflow will use a local directory to keep track of all executions from your laptop,\neven if you are using Amazon S3 as datastore or AWS Batch for\n",(0,n.kt)("a",{parentName:"p",href:"/v/r/metaflow-on-aws/#compute"},"compute"),". You can use a local Jupyter notebook to interact\nwith data artifacts from all your previous executions as well as currently running ones.\nHowever, deploying the metaflow service ","(","as well as Amazon S3 as datastore",")"," is helpful\nif you would like to share results with your peers and track your work without fear of\nlosing any state."),(0,n.kt)("p",null,"At Netflix, all executions are logged in the metaflow service and all data artifacts are\nstored in Amazon S3, so that any data scientist can interface with anybody's work via\nthe ",(0,n.kt)("a",{parentName:"p",href:"/v/r/metaflow/client"},"client")," and collaborate fruitfully. Also, a centralized\nmetaflow service along with a data store like Amazon S3 makes it easy for data\nscientists at Netflix to use hosted notebooks to easily set-up dashboards to monitors\ntheir flows."),(0,n.kt)("h3",{id:"notebooks"},"Notebooks"),(0,n.kt)("p",null,"We are a ",(0,n.kt)("a",{parentName:"p",href:"https://netflixtechblog.com/notebook-innovation-591ee3221233"},"big fan of\nNotebooks")," at Netflix.\nWith Metaflow, users can easily create custom dashboards to monitor the execution of\ntheir Metaflow flows and track how their models are behaving in a very seamless manner.\nThey can do that on their laptops with a local notebook or in the cloud with a hosted\nnotebook solution. One such hosted solution is ",(0,n.kt)("a",{parentName:"p",href:"https://aws.amazon.com/sagemaker/"},"Sagemaker\nNotebooks")," by AWS. For notebooks hosted in the cloud,\nyou would want to ensure that you have configured the ",(0,n.kt)("a",{parentName:"p",href:"/v/r/metaflow-on-aws/#metadata"},"metaflow\nservice")," and are using Amazon S3 for\n",(0,n.kt)("a",{parentName:"p",href:"/v/r/metaflow-on-aws/#datastore"},"datastore"),"."),(0,n.kt)("h3",{id:"scheduling"},"Scheduling"),(0,n.kt)("p",null,"With Metaflow, users can create, prototype and execute flows from their laptops that can\nscale easily by leveraging elastic storage and compute capabilities in the cloud. Often,\nthere comes a time, when these flows need to be run autonomously without any user\nintervention. At that point, Metaflow makes it easy to move the flow execution from\nMetaflow to AWS Step Functions to leverage all the feature sets that you get from a\nproduction grade scheduler - high availability, monitoring, reliability, etc. In\naddition, with AWS EventBridge, users can set triggers to execute these flows on a\nschedule automatically."),(0,n.kt)("h2",{id:"using-metaflow-with-aws"},"Using Metaflow with AWS"),(0,n.kt)("p",null,"When you install Metaflow for the first time, you start in the local mode. Artifacts and\nmetadata are stored in a local directory and computation is performed with local\nprocesses. This mode is perfectly fine for personal use but if your use case involves\nmore people and/or data, we recommend that you configure Metaflow to use AWS."),(0,n.kt)("p",null,"Even after Metaflow has been configured to use AWS, users can still choose to use local\ntools, e.g. for rapid prototyping. The easy back-and-forth between local and remote is a\nkey value proposition of Metaflow. However, we recommend that you enable ",(0,n.kt)("strong",{parentName:"p"},"metadata"),"\nand ",(0,n.kt)("strong",{parentName:"p"},"datastore")," to use AWS by default, which makes sure that all data stays persistent\nand everyone in the organization can benefit from the results of workflows."),(0,n.kt)("p",null,"Netflix uses this setup internally. To make the experience smoother, Netflix's data\nscientists are provided with a ","(","shared",")"," EC2 instance where they can develop and test\nMetaflow code with minimal latency between their development environment and S3. Note\nthat many IDEs such as ",(0,n.kt)("a",{parentName:"p",href:"https://code.visualstudio.com/"},"VSCode")," or\n",(0,n.kt)("a",{parentName:"p",href:"https://rstudio.com/"},"RStudio")," support execution on a remote instance natively."),(0,n.kt)("h2",{id:"next-steps"},"Next Steps"),(0,n.kt)("p",null,"If your organization doesn't have an AWS account already, we provide a hosted sandbox\nenvironment where you can test Metaflow using your own code and data, to get a feel of\nthe benefits of AWS. Read more in the section about ",(0,n.kt)("a",{parentName:"p",href:"https://metaflow.org/sandbox"},"Metaflow\nSandbox"),"."),(0,n.kt)("p",null,"If your organization has an AWS account already, see our ",(0,n.kt)("a",{parentName:"p",href:"https://outerbounds.com/docs/admin/metaflow-on-aws/deployment-guide"},"deployment\nguide")," for detailed\ninstructions on how to configure your account for Metaflow."),(0,n.kt)("p",null,"If you are already using Metaflow in your AWS account, and want to get started with how\nto manage various AWS resources, take a look at our ",(0,n.kt)("a",{parentName:"p",href:"https://outerbounds.com/docs/admin/metaflow-on-aws/operations-guide"},"operations\nguide"),"."))}p.isMDXComponent=!0}}]);