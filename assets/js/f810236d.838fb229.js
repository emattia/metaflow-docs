"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[6612],{9577:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>g,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var o=n(7462),r=(n(7294),n(3905)),a=n(2004);const i={},l="Deploying Variants of Event-Triggered Flows",s={unversionedId:"production/event-triggering/project-events",id:"production/event-triggering/project-events",title:"Deploying Variants of Event-Triggered Flows",description:"Consider this advanced scenario: You have deployed two flows [linked together",source:"@site/docs/production/event-triggering/project-events.md",sourceDirName:"production/event-triggering",slug:"/production/event-triggering/project-events",permalink:"/production/event-triggering/project-events",draft:!1,editUrl:"https://github.dev/Netflix/metaflow-docs/blob/master/docs/production/event-triggering/project-events.md",tags:[],version:"current",frontMatter:{},sidebar:"python",previous:{title:"Inspecting Events",permalink:"/production/event-triggering/inspect-events"},next:{title:"Metaflow API reference",permalink:"/api/"}},p={},c=[{value:"Using <code>@project</code> and <code>@trigger_on_finish</code> together",id:"using-project-and-trigger_on_finish-together",level:2},{value:"Deploying a parallel branch",id:"deploying-a-parallel-branch",level:3},{value:"Triggering across branches",id:"triggering-across-branches",level:2}],d={toc:c};function g(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,o.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"deploying-variants-of-event-triggered-flows"},"Deploying Variants of Event-Triggered Flows"),(0,r.kt)("p",null,"Consider this advanced scenario: You have deployed two flows ",(0,r.kt)("a",{parentName:"p",href:"/production/event-triggering/flow-events#passing-data-across-flows"},"linked together\nvia ",(0,r.kt)("inlineCode",{parentName:"a"},"@trigger_on_finish")),".\nThe flows run happily in production. At some point, you want to experiment with a new\nmodeling approach. In order to know if the new approach works better than the\ncurrent production version, you'd like to run them concurrently using the same\ndata, maybe powering an A/B test."),(0,r.kt)("p",null,"It is critical that the experimental variant doesn't interfere with the\nproduction version. Conceptually, you would like to have two isolated\ndeployments like here:"),(0,r.kt)(a.Z,{playsinline:!0,playing:!0,controls:!0,muted:!0,loop:!0,url:"/assets/et-variants.mp4",width:"100%",height:"100%",mdxType:"ReactPlayer"}),(0,r.kt)("p",null,"Fortunately, you can achieve such isolated deployments by using ",(0,r.kt)("a",{parentName:"p",href:"/production/coordinating-larger-metaflow-projects"},"the ",(0,r.kt)("inlineCode",{parentName:"a"},"@project"),"\ndecorator")," in conjunction\nwith ",(0,r.kt)("inlineCode",{parentName:"p"},"@trigger_on_finish"),"."),(0,r.kt)("h2",{id:"using-project-and-trigger_on_finish-together"},"Using ",(0,r.kt)("inlineCode",{parentName:"h2"},"@project")," and ",(0,r.kt)("inlineCode",{parentName:"h2"},"@trigger_on_finish")," together"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from metaflow import FlowSpec, step, current, project\n\n@project(name='variant_demo')\nclass FirstProjectFlow(FlowSpec):\n\n    @step\n    def start(self):\n        print(\"This deployment is called\", current.project_flow_name)\n        self.next(self.end)\n\n    @step\n    def end(self):\n        pass\n\nif __name__ == '__main__':\n    FirstProjectFlow()\n")),(0,r.kt)("p",null,"and "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from metaflow import FlowSpec, step, trigger_on_finish, current, project\n\n@trigger_on_finish(flow='FirstProjectFlow')\n@project(name='variant_demo')\nclass SecondProjectFlow(FlowSpec):\n\n    @step\n    def start(self):\n        print(\"This deployment is called\", current.project_flow_name)\n        print(\"This run was triggered by\", current.trigger.event)\n        self.next(self.end)\n\n    @step\n    def end(self):\n        pass\n\nif __name__ == '__main__':\n    SecondProjectFlow()\n")),(0,r.kt)("p",null,"Deploy both the flows on Argo Workflows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"python firstproject.py argo-workflows create\npython secondproject.py argo-workflows create\n")),(0,r.kt)("p",null,"and trigger the first one manually:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"python firstproject.py argo-workflows trigger\n")),(0,r.kt)("p",null,"Thanks to ",(0,r.kt)("inlineCode",{parentName:"p"},"@project"),", the flows are deployed with a special name that includes a\nbranch prefix. By default,\n",(0,r.kt)("a",{parentName:"p",href:"/production/coordinating-larger-metaflow-projects#single-flow-multiple-developers"},"each user gets their own\nprefix"),",\nso the output of the ",(0,r.kt)("inlineCode",{parentName:"p"},"start")," step of ",(0,r.kt)("inlineCode",{parentName:"p"},"FirstProjectFlow")," should look\nlike:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"The deployment is called variant_demo.user.alice.FirstProjectFlow\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"SecondProjectFlow")," starts automatically when ",(0,r.kt)("inlineCode",{parentName:"p"},"FirstProjectFlow")," completes.\nIt should show output like here:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"This deployment is called variant_demo.user.alice.SecondProjectFlow\nThis run was triggered by\nMetaflowEvent(name='metaflow.variant_demo.user.alice.FirstProjectFlow.end', ...)\n")),(0,r.kt)("p",null,"which indicates that the event triggering the run is specific to Alice."),(0,r.kt)("h3",{id:"deploying-a-parallel-branch"},"Deploying a parallel branch"),(0,r.kt)("p",null,"To deploy a parallel variant or ",(0,r.kt)("em",{parentName:"p"},"a branch")," - in the sense of Git branches -\nexecute the following commands:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"python firstproject.py --branch new_model argo-workflows create\npython secondproject.py --branch new_model argo-workflows create\n")),(0,r.kt)("p",null,"and trigger the branch like here:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"python firstproject.py --branch new_model argo-workflows trigger\n")),(0,r.kt)("p",null,"You should see a corresponding output for these runs. Importantly, triggering\nthe ",(0,r.kt)("inlineCode",{parentName:"p"},"new_model")," branch doesn't have any effect on Alice's deployment, which is\n",(0,r.kt)("a",{parentName:"p",href:"/scaling/tagging"},"fully isolated in its own namespace"),"."),(0,r.kt)("h2",{id:"triggering-across-branches"},"Triggering across branches"),(0,r.kt)("p",null,"As shown above, ",(0,r.kt)("inlineCode",{parentName:"p"},"@project")," guarantees that all flows linked together within the\nsame project and branch are isolated from other deployments. However, sometimes\nyou may want to depend on an upstream flow that is deployed outside of your\nbranch. For instance, you may want to deploy a variant of a downstream\nworkflow, like ",(0,r.kt)("inlineCode",{parentName:"p"},"SecondProjectFlow")," above, while reusing results from an\nexisting upstream flow, like ",(0,r.kt)("inlineCode",{parentName:"p"},"FirstProjectFlow"),"."),(0,r.kt)("p",null,"You can accomplish this by specifying explicitly the project-branch name that\nyou want to depend on. For instance, this line makes a flow depend on Alice's\ndeployment regardless of the branch the flow is deployed on:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"@trigger_on_finish(flow='variant_demo.user.alice.FirstProjectFlow')\n")))}g.isMDXComponent=!0}}]);