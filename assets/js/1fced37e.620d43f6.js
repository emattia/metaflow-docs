"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[6002],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>d});var n=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},u=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,l=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),h=p(a),d=i,c=h["".concat(s,".").concat(d)]||h[d]||m[d]||l;return a?n.createElement(c,r(r({ref:t},u),{},{components:a})):n.createElement(c,r({ref:t},u))}));function d(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var l=a.length,r=new Array(l);r[0]=h;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:i,r[1]=o;for(var p=2;p<l;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}h.displayName="MDXCreateElement"},4519:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>m,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var n=a(7462),i=(a(7294),a(3905));const l={},r="Release Notes",o={unversionedId:"internals/release-notes",id:"internals/release-notes",title:"Release Notes",description:"Read below how Metaflow has improved over time.",source:"@site/docs/internals/release-notes.md",sourceDirName:"internals",slug:"/internals/release-notes",permalink:"/internals/release-notes",draft:!1,editUrl:"https://github.dev/Netflix/metaflow-docs/blob/master/docs/internals/release-notes.md",tags:[],version:"current",frontMatter:{},sidebar:"python",previous:{title:"@trigger_on_finish",permalink:"/api/flow-decorators/trigger_on_finish"},next:{title:"Technical Overview",permalink:"/internals/technical-overview"}},s={},p=[{value:"2.6.1 (May 13, 2022)",id:"261-may-13-2022",level:2},{value:"2.6.0 (Apr 25, 2022)",id:"260-apr-25-2022",level:2},{value:"Add capability to launch Metaflow tasks on Kubernetes and schedule Metaflow flows with Argo Workflows.",id:"add-capability-to-launch-metaflow-tasks-on-kubernetes-and-schedule-metaflow-flows-with-argo-workflows",level:4},{value:"Expose <code>tags</code> in <code>current</code> object.",id:"expose-tags-in-current-object",level:4},{value:"2.5.4 (Mar 24, 2022)",id:"254-mar-24-2022",level:2},{value:"2.5.3 (Mar 7, 2022)",id:"253-mar-7-2022",level:2},{value:"2.5.2 (Feb 16, 2022)",id:"252-feb-16-2022",level:2},{value:"2.5.1 (Feb 15, 2022)",id:"251-feb-15-2022",level:2},{value:"2.5.0 (Jan 25, 2022)",id:"250-jan-25-2022",level:2},{value:"2.4.9 (Jan 18, 2022)",id:"249-jan-18-2022",level:2},{value:"2.4.8 (Jan 10, 2022)",id:"248-jan-10-2022",level:2},{value:"2.4.7 (Dec 16, 2021)",id:"247-dec-16-2021",level:2},{value:"2.4.6 (Dec 16, 2021)",id:"246-dec-16-2021",level:2},{value:"2.4.5 (Dec 8, 2021)",id:"245-dec-8-2021",level:2},{value:"2.4.4 (Nov 29, 2021)",id:"244-nov-29-2021",level:2},{value:'Improvements <a href="#user-content-v2.4.4_improvements" id="user-content-v2.4.4_improvements"></a>',id:"improvements-",level:3},{value:"Add default image config option as described in #489 (#813)",id:"add-default-image-config-option-as-described-in-489-813",level:4},{value:"Read default k8s namespace from config (#823)",id:"read-default-k8s-namespace-from-config-823",level:4},{value:"2.4.3 (Nov 3rd 2021)",id:"243-nov-3rd-2021",level:2},{value:'Bug Fixes <a href="#user-content-v2.4.3_bugs" id="user-content-v2.4.3_bugs"></a>',id:"bug-fixes-",level:3},{value:'Fix a race condition when accessing artifacts of a running task (#789) <a href="#user-content-789" id="user-content-789"></a>',id:"fix-a-race-condition-when-accessing-artifacts-of-a-running-task-789-",level:4},{value:'Fix an issue when using a combination of <code>@catch</code> and <code>@retry</code> decorators (#776) <a href="#user-content-776" id="user-content-776"></a>',id:"fix-an-issue-when-using-a-combination-of-catch-and-retry-decorators-776-",level:4},{value:'Upgrade Pandas in tutorials (#707) <a href="#user-content-707" id="user-content-707"></a>',id:"upgrade-pandas-in-tutorials-707-",level:4},{value:"2.4.2 (Oct 25th, 2021)",id:"242-oct-25th-2021",level:2},{value:"Bug Fixes",id:"bug-fixes",level:3},{value:"Fix a bug with accessing legacy logs through <code>metaflow.client</code> (#779)",id:"fix-a-bug-with-accessing-legacy-logs-through-metaflowclient-779",level:4},{value:"Fix a bug with task datastore access when no task attempt has been recorded (#780)",id:"fix-a-bug-with-task-datastore-access-when-no-task-attempt-has-been-recorded-780",level:4},{value:"2.4.1 (Oct 18th, 2021)",id:"241-oct-18th-2021",level:2},{value:"Bug Fixes",id:"bug-fixes-1",level:3},{value:"Expose non-pythonic dependencies inside the conda environment on AWS Batch (#735)",id:"expose-non-pythonic-dependencies-inside-the-conda-environment-on-aws-batch-735",level:4},{value:"New Features",id:"new-features",level:3},{value:"Introduce size properties for artifacts and logs in metaflow.client (#752)",id:"introduce-size-properties-for-artifacts-and-logs-in-metaflowclient-752",level:4},{value:"Expose attempt level task properties (#725)",id:"expose-attempt-level-task-properties-725",level:4},{value:"Introduce @kubernetes decorator for launching Metaflow tasks on Kubernetes (#644)",id:"introduce-kubernetes-decorator-for-launching-metaflow-tasks-on-kubernetes-644",level:4},{value:"2.4.0 (Oct 4th, 2021)",id:"240-oct-4th-2021",level:2},{value:"Breaking Changes",id:"breaking-changes",level:3},{value:"Change return type of created_at/finished_at in the client (#692)",id:"change-return-type-of-created_atfinished_at-in-the-client-692",level:4},{value:"Bug Fixes",id:"bug-fixes-2",level:3},{value:"Better error messages in case of a Conda issue (#706)",id:"better-error-messages-in-case-of-a-conda-issue-706",level:4},{value:"Fix error message in Metadata service (#712)",id:"fix-error-message-in-metadata-service-712",level:4},{value:"New Features",id:"new-features-1",level:3},{value:"S3 retry counts are now configurable (#700)",id:"s3-retry-counts-are-now-configurable-700",level:4},{value:"New datastore implementation resulting in improved performance (#580)",id:"new-datastore-implementation-resulting-in-improved-performance-580",level:4},{value:"S3 datatools performance improvements (#697)",id:"s3-datatools-performance-improvements-697",level:4},{value:"2.3.6 (Sep 8th, 2021)",id:"236-sep-8th-2021",level:2},{value:"Bug Fixes",id:"bug-fixes-3",level:3},{value:"Fix recursion error when <code>METAFLOW_DEFAULT_ENVIRONMENT</code> is set to <code>conda</code>",id:"fix-recursion-error-when-metaflow_default_environment-is-set-to-conda",level:4},{value:"Allow dots in <code>host_volumes</code> attribute for <code>@batch</code> decorator",id:"allow-dots-in-host_volumes-attribute-for-batch-decorator",level:4},{value:"2.3.5 (Aug 23rd, 2021)",id:"235-aug-23rd-2021",level:2},{value:"Features",id:"features",level:3},{value:"Enable mounting host volumes in AWS Batch",id:"enable-mounting-host-volumes-in-aws-batch",level:4},{value:"Bug Fixes",id:"bug-fixes-4",level:3},{value:"Fix input values for Parameters of type <code>list</code> within a Metaflow Foreach task",id:"fix-input-values-for-parameters-of-type-list-within-a-metaflow-foreach-task",level:4},{value:"2.3.4 (Aug 11th, 2021)",id:"234-aug-11th-2021",level:2},{value:"Bug Fixes",id:"bug-fixes-5",level:3},{value:"Fix execution of <code>step-functions create</code> when using an <code>IncludeFile</code> parameter",id:"fix-execution-of-step-functions-create-when-using-an-includefile-parameter",level:4},{value:"2.3.3 (Jul 29th, 2021)",id:"233-jul-29th-2021",level:2},{value:"Features",id:"features-1",level:3},{value:"Support resource tags for Metaflow&#39;s integration with AWS Batch",id:"support-resource-tags-for-metaflows-integration-with-aws-batch",level:4},{value:"Bug Fixes",id:"bug-fixes-6",level:3},{value:"Properly handle <code>None</code> as defaults for parameters for AWS Step Functions execution",id:"properly-handle-none-as-defaults-for-parameters-for-aws-step-functions-execution",level:4},{value:"Fix return value of <code>IncludeFile</code> artifacts",id:"fix-return-value-of-includefile-artifacts",level:4},{value:"2.3.2 (Jun 29th, 2021)",id:"232-jun-29th-2021",level:2},{value:"Features",id:"features-2",level:3},{value:"2.3.1 (Jun 23rd, 2021)",id:"231-jun-23rd-2021",level:2},{value:"Features",id:"features-3",level:3},{value:"2.3.0 (May 27th, 2021)",id:"230-may-27th-2021",level:2},{value:"Features",id:"features-4",level:3},{value:"Coordinate larger Metaflow projects with <code>@project</code>",id:"coordinate-larger-metaflow-projects-with-project",level:4},{value:"Hyphenated-parameters support in AWS Step Functions",id:"hyphenated-parameters-support-in-aws-step-functions",level:4},{value:"State Machine execution history logging for AWS Step Functions",id:"state-machine-execution-history-logging-for-aws-step-functions",level:4},{value:"2.2.13 (May 19th, 2021)",id:"2213-may-19th-2021",level:2},{value:"Bug Fixes",id:"bug-fixes-7",level:3},{value:"Handle regression with <code>@batch</code> execution on certain docker images",id:"handle-regression-with-batch-execution-on-certain-docker-images",level:4},{value:"2.2.12 (May 18th, 2021)",id:"2212-may-18th-2021",level:2},{value:"Features",id:"features-5",level:3},{value:"Add capability to override AWS Step Functions state machine name while deploying flows to AWS Step Functions",id:"add-capability-to-override-aws-step-functions-state-machine-name-while-deploying-flows-to-aws-step-functions",level:4},{value:"Introduce heartbeats for Metaflow flows",id:"introduce-heartbeats-for-metaflow-flows",level:4},{value:"Bug Fixes",id:"bug-fixes-8",level:3},{value:"Handle regression with <code>Click &gt;=8.0.x</code>",id:"handle-regression-with-click-80x",level:4},{value:"2.2.11 (Apr 30th, 2021)",id:"2211-apr-30th-2021",level:2},{value:"Bug Fixes",id:"bug-fixes-9",level:3},{value:"Fix regression that broke compatibility with Python 2.7",id:"fix-regression-that-broke-compatibility-with-python-27",level:4},{value:"2.2.10 (Apr 22nd, 2021)",id:"2210-apr-22nd-2021",level:2},{value:"Features",id:"features-6",level:3},{value:"AWS Logs Group, Region and Stream are now available in metadata for tasks executed on AWS Batch",id:"aws-logs-group-region-and-stream-are-now-available-in-metadata-for-tasks-executed-on-aws-batch",level:4},{value:"Execution logs are now available for all tasks in Metaflow universe",id:"execution-logs-are-now-available-for-all-tasks-in-metaflow-universe",level:4},{value:"Bug Fixes",id:"bug-fixes-10",level:3},{value:"Fix regression with <code>ping/</code> endpoint for Metadata service",id:"fix-regression-with-ping-endpoint-for-metadata-service",level:4},{value:"Fix the behaviour of <code>--namespace=</code> CLI args when executing a flow",id:"fix-the-behaviour-of---namespace-cli-args-when-executing-a-flow",level:4},{value:"2.2.9 (Apr 19th, 2021)",id:"229-apr-19th-2021",level:2},{value:"Bugs",id:"bugs",level:3},{value:"Remove pinned pylint dependency",id:"remove-pinned-pylint-dependency",level:4},{value:"Improve handling of <code>/</code> in image parameter for batch",id:"improve-handling-of--in-image-parameter-for-batch",level:4},{value:"List custom FlowSpec parameters in the intended order",id:"list-custom-flowspec-parameters-in-the-intended-order",level:4},{value:"2.2.8 (Mar 15th, 2021)",id:"228-mar-15th-2021",level:2},{value:"Bugs",id:"bugs-1",level:3},{value:"Fix <code>@environment</code> behavior for conflicting attribute values",id:"fix-environment-behavior-for-conflicting-attribute-values",level:4},{value:"Fix <code>environment is not callable</code> error when using <code>@environment</code>",id:"fix-environment-is-not-callable-error-when-using-environment",level:4},{value:"2.2.7 (Feb 8th, 2021)",id:"227-feb-8th-2021",level:2},{value:"Bugs",id:"bugs-2",level:3},{value:"Handle for-eaches properly for AWS Step Functions workflows running on AWS Fargate",id:"handle-for-eaches-properly-for-aws-step-functions-workflows-running-on-aws-fargate",level:4},{value:"2.2.6 (Jan 26th, 2021)",id:"226-jan-26th-2021",level:2},{value:"Features",id:"features-7",level:3},{value:"Support AWS Fargate as compute backend for Metaflow tasks launched on AWS Batch",id:"support-aws-fargate-as-compute-backend-for-metaflow-tasks-launched-on-aws-batch",level:4},{value:"Support <code>shared_memory</code>, <code>max_swap</code>, <code>swappiness</code> attributes for Metaflow tasks launched on AWS Batch",id:"support-shared_memory-max_swap-swappiness-attributes-for-metaflow-tasks-launched-on-aws-batch",level:4},{value:"Support wider very-wide workflows on top of AWS Step Functions",id:"support-wider-very-wide-workflows-on-top-of-aws-step-functions",level:4},{value:"Bug Fixes",id:"bug-fixes-11",level:3},{value:"Assign tags to <code>Run</code> objects generated through AWS Step Functions executions",id:"assign-tags-to-run-objects-generated-through-aws-step-functions-executions",level:4},{value:"Pipe all workflow set-up logs to <code>stderr</code>",id:"pipe-all-workflow-set-up-logs-to-stderr",level:4},{value:"Handle null assignment to <code>IncludeFile</code> properly",id:"handle-null-assignment-to-includefile-properly",level:4},{value:"2.2.5 (Nov 11th, 2020)",id:"225-nov-11th-2020",level:2},{value:"Features",id:"features-8",level:3},{value:"Log <code>metaflow_version:</code> and <code>runtime:</code> tag for all executions",id:"log-metaflow_version-and-runtime-tag-for-all-executions",level:4},{value:"Bug Fixes",id:"bug-fixes-12",level:3},{value:"Handle inconsistently cased file system issue when creating @conda environments on macOS for linux-64",id:"handle-inconsistently-cased-file-system-issue-when-creating-conda-environments-on-macos-for-linux-64",level:4},{value:"2.2.4 (Oct 28th, 2020)",id:"224-oct-28th-2020",level:2},{value:"Features",id:"features-9",level:3},{value:"Metaflow is now compliant with AWS GovCloud &amp; AWS CN regions",id:"metaflow-is-now-compliant-with-aws-govcloud--aws-cn-regions",level:4},{value:"Bug Fixes",id:"bug-fixes-13",level:3},{value:"Address a bug with overriding the default value for IncludeFile",id:"address-a-bug-with-overriding-the-default-value-for-includefile",level:4},{value:"Port AWS region check for AWS DynamoDb from <code>curl</code> to <code>requests</code>",id:"port-aws-region-check-for-aws-dynamodb-from-curl-to-requests",level:4},{value:"2.2.3 (Sept 8th, 2020)",id:"223-sept-8th-2020",level:2},{value:"Bug Fixes",id:"bug-fixes-14",level:3},{value:"Fix issue #305 : Default &#39;help&#39; for parameters was not handled properly",id:"fix-issue-305--default-help-for-parameters-was-not-handled-properly",level:4},{value:"Pin the conda library versions for Metaflow default dependencies based on the Python version",id:"pin-the-conda-library-versions-for-metaflow-default-dependencies-based-on-the-python-version",level:4},{value:"Add conda bin path to the PATH environment variable during Metaflow step execution",id:"add-conda-bin-path-to-the-path-environment-variable-during-metaflow-step-execution",level:4},{value:"2.2.2 (Aug 20th, 2020)",id:"222-aug-20th-2020",level:2},{value:"Bug Fixes",id:"bug-fixes-15",level:3},{value:"Fix a regression with Conda",id:"fix-a-regression-with-conda",level:4},{value:"Clarify Pandas version needed for Episode 04",id:"clarify-pandas-version-needed-for-episode-04",level:4},{value:"Fix an issue with the metadata service",id:"fix-an-issue-with-the-metadata-service",level:4},{value:"2.2.1 (Aug 17th, 2020)",id:"221-aug-17th-2020",level:2},{value:"Features",id:"features-10",level:3},{value:"Add <code>include</code> parameter for <code>merge_artifacts</code>",id:"add-include-parameter-for-merge_artifacts",level:4},{value:"Bug Fixes",id:"bug-fixes-16",level:3},{value:"Fix a regression with datatools",id:"fix-a-regression-with-datatools",level:4},{value:"Fix an issue with Conda in certain environments",id:"fix-an-issue-with-conda-in-certain-environments",level:4},{value:"Fix an issue with the S3 datastore in case of retries",id:"fix-an-issue-with-the-s3-datastore-in-case-of-retries",level:4},{value:"2.2.0 (Aug 4th, 2020)",id:"220-aug-4th-2020",level:2},{value:"Features",id:"features-11",level:3},{value:"Support for R lang.",id:"support-for-r-lang",level:4},{value:"2.1.1 (Jul 30th, 2020)",id:"211-jul-30th-2020",level:2},{value:"Bug Fixes",id:"bug-fixes-17",level:3},{value:"Handle race condition for <code>/step</code> endpoint of metadata service.",id:"handle-race-condition-for-step-endpoint-of-metadata-service",level:4},{value:"2.1.0 (Jul 29th, 2020)",id:"210-jul-29th-2020",level:2},{value:"Features",id:"features-12",level:3},{value:"Add capability to schedule Metaflow flows with AWS Step Functions.",id:"add-capability-to-schedule-metaflow-flows-with-aws-step-functions",level:4},{value:"Improvements",id:"improvements",level:3},{value:"Fix log indenting in Metaflow.",id:"fix-log-indenting-in-metaflow",level:4},{value:"Throw exception properly if fetching code package from Amazon S3 on AWS Batch fails.",id:"throw-exception-properly-if-fetching-code-package-from-amazon-s3-on-aws-batch-fails",level:4},{value:"Remove millisecond information from timestamps returned by Metaflow client.",id:"remove-millisecond-information-from-timestamps-returned-by-metaflow-client",level:4},{value:"Handle CloudWatchLogs resource creation delay gracefully.",id:"handle-cloudwatchlogs-resource-creation-delay-gracefully",level:4},{value:"2.0.5 (Apr 30th, 2020)",id:"205-apr-30th-2020",level:2},{value:'Improvements <a href="#2-0-5-improvements" id="2-0-5-improvements"></a>',id:"improvements--1",level:3},{value:"Fix logging of prefixes in datatools.S3._read_many_files",id:"fix-logging-of-prefixes-in-datatoolss3_read_many_files",level:4},{value:"Increase retry count for AWS Batch logs streaming.",id:"increase-retry-count-for-aws-batch-logs-streaming",level:4},{value:"Upper-bound pylint version to &lt; 2.5.0.",id:"upper-bound-pylint-version-to--250",level:4},{value:"2.0.4 (Apr 28th, 2020)",id:"204-apr-28th-2020",level:2},{value:'Improvements <a href="#2-0-4-improvements" id="2-0-4-improvements"></a>',id:"improvements--2",level:3},{value:"Expose <code>retry_count</code> in <code>Current</code>",id:"expose-retry_count-in-current",level:4},{value:"Mute superfluous <code>ThrottleExceptions</code> in AWS Batch job logs",id:"mute-superfluous-throttleexceptions-in-aws-batch-job-logs",level:4},{value:'Bug Fixes <a href="#2-0-4-bug-fixes" id="2-0-4-bug-fixes"></a>',id:"bug-fixes--1",level:3},{value:"Set proper thresholds for retrying <code>DescribeJobs</code> API for AWS Batch",id:"set-proper-thresholds-for-retrying-describejobs-api-for-aws-batch",level:4},{value:"Explicitly override <code>PYTHONNOUSERSITE</code> for <code>conda</code> environments",id:"explicitly-override-pythonnousersite-for-conda-environments",level:4},{value:"Preempt AWS Batch job log collection when the job fails to get into a <code>RUNNING</code> state",id:"preempt-aws-batch-job-log-collection-when-the-job-fails-to-get-into-a-running-state",level:4},{value:"2.0.3 (Mar 6th, 2020)",id:"203-mar-6th-2020",level:2},{value:"Improvements",id:"improvements-1",level:3},{value:"Parameter listing",id:"parameter-listing",level:4},{value:"Usability improvements",id:"usability-improvements",level:4},{value:"Performance",id:"performance",level:3},{value:"Conda",id:"conda",level:4},{value:"Bug Fixes",id:"bug-fixes-18",level:3},{value:"Executing on AWS Batch",id:"executing-on-aws-batch",level:4},{value:"2.0.2 (Feb 11th, 2020)",id:"202-feb-11th-2020",level:2},{value:"2.0.1 (Dec 16th, 2019)",id:"201-dec-16th-2019",level:2},{value:"2.0.0 (Dec 3rd, 2019)",id:"200-dec-3rd-2019",level:2},{value:"Hello World!",id:"hello-world",level:4},{value:"Releases pre-2.0.0 were internal to Netflix",id:"releases-pre-200-were-internal-to-netflix",level:2}],u={toc:p};function m(e){let{components:t,...a}=e;return(0,i.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"release-notes"},"Release Notes"),(0,i.kt)("p",null,"Read below how Metaflow has improved over time."),(0,i.kt)("p",null,"We take backwards compatibility very seriously. In the vast majority of cases, you can\nupgrade Metaflow without expecting changes in your existing code. In the rare cases when\nbreaking changes are absolutely necessary, usually, due to bug fixes, you can take a\nlook at minor breaking changes below before you upgrade."),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"For the most recent release notes, see ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/releases"},"release notes on\nGithub"))),(0,i.kt)("h2",{id:"261-may-13-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.6.1"},"2.6.1 (May 13, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.6.1 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Proper support for custom S3 endpoints. This enables using S3-compatible object\nstorages like MinIO or Dell EMC-ECS as data stores for Metaflow\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/1045"},"#1045"),")"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Bug fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fixed card rendering for tables with some NaN values\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/1023"},"#1023"),")  in\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/1025"},"#1025")),(0,i.kt)("li",{parentName:"ul"},"current.pathspec to return None when used outside Flow in\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/1033"},"#1033")),(0,i.kt)("li",{parentName:"ul"},"Fixed bug in the ",(0,i.kt)("inlineCode",{parentName:"li"},"card list")," command in\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/1044"},"#1044")),(0,i.kt)("li",{parentName:"ul"},"Fixed issues with S3 get and ranges in\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/1034"},"#1034")),(0,i.kt)("li",{parentName:"ul"},"Fix ",(0,i.kt)("inlineCode",{parentName:"li"},"_new_task")," calling bug in LocalMetadataProvider in\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/1046"},"#1046"))))),(0,i.kt)("h2",{id:"260-apr-25-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.6.0"},"2.6.0 (Apr 25, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.6.0 release is a minor release and introduces Metaflow's integration with\n",(0,i.kt)("a",{parentName:"p",href:"https://docs.metaflow.org/scaling/introduction/effortless-scaling-with-kubernetes"},"Kubernetes"),"\nand ",(0,i.kt)("a",{parentName:"p",href:"https://docs.metaflow.org/production/scheduling-metaflow-flows/introduction/scheduling-with-argo-workflows"},"Argo\nWorkflows")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Add capability to launch Metaflow tasks on Kubernetes and schedule Metaflow flows\nwith Argo Workflows."),(0,i.kt)("li",{parentName:"ul"},"Expose ",(0,i.kt)("inlineCode",{parentName:"li"},"tags")," in ",(0,i.kt)("inlineCode",{parentName:"li"},"current")," object.")))),(0,i.kt)("h4",{id:"add-capability-to-launch-metaflow-tasks-on-kubernetes-and-schedule-metaflow-flows-with-argo-workflows"},"Add capability to launch Metaflow tasks on Kubernetes and schedule Metaflow flows with Argo Workflows."),(0,i.kt)("p",null,"This release enables brand new capabilities for ",(0,i.kt)("a",{parentName:"p",href:"https://outerbounds.com/blog/human-centric-data-science-on-kubernetes-with-metaflow/"},"Metaflow on top of\nKubernetes"),".\nYou can now ",(0,i.kt)("a",{parentName:"p",href:"https://docs.metaflow.org/scaling/introduction/effortless-scaling-with-kubernetes"},(0,i.kt)("inlineCode",{parentName:"a"},"run --with\nkubernetes")),"\nall or parts of any Metaflow flow on top of ",(0,i.kt)("em",{parentName:"p"},"any")," Kubernetes cluster from your\nworkstation. To execute your flow asynchronously, you can deploy the flow to Argo\nWorkflows (a Kubernetes-native workflow scheduler) with a single command -\n",(0,i.kt)("a",{parentName:"p",href:"https://docs.metaflow.org/production/scheduling-metaflow-flows/introduction/scheduling-with-argo-workflows"},(0,i.kt)("inlineCode",{parentName:"a"},"argo-workflows\ncreate")),"."),(0,i.kt)("p",null,"To get started, take a look at the ",(0,i.kt)("a",{parentName:"p",href:"https://outerbounds.com/docs/engineering-welcome/"},"deployment guide for\nKubernetes"),". Your feedback and\nfeature requests are highly appreciated! - please reach out to us at\nslack.outerbounds.co"),(0,i.kt)("p",null,"PR #992 addressed issue #50."),(0,i.kt)("h4",{id:"expose-tags-in-current-object"},"Expose ",(0,i.kt)("inlineCode",{parentName:"h4"},"tags")," in ",(0,i.kt)("inlineCode",{parentName:"h4"},"current")," object."),(0,i.kt)("p",null,"Metaflow tags are now available as part of the ",(0,i.kt)("inlineCode",{parentName:"p"},"current")," singleton object."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"@step\ndef my_step(self):\n    from metaflow import current\n    tags = current.tags\n    ...\n")),(0,i.kt)("p",null,"PR #1019 fixed issue #1007."),(0,i.kt)("h2",{id:"254-mar-24-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.5.4"},"2.5.4 (Mar 24, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.5.4 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Card bug fixes (",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/989"},"#989"),",\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/981"},"#981")," )"),(0,i.kt)("li",{parentName:"ul"},"importlib_metadata fixes for Python 3.5\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/988"},"#988")," )"),(0,i.kt)("li",{parentName:"ul"},"Configurable temp root when pulling artifacts from s3\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/991"},"#991"),")")))),(0,i.kt)("h2",{id:"253-mar-7-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.5.3"},"2.5.3 (Mar 7, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.5.3 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Bug fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},'Fix "Too many symbolic links" error when using Conda + Batch on macOS in\n',(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/972"},"#972")),(0,i.kt)("li",{parentName:"ul"},"Emit app tag for AWS Batch jobs (\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/970"},"#970")," )")))),(0,i.kt)("h2",{id:"252-feb-16-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.5.2"},"2.5.2 (Feb 16, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.5.2 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Improvements",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"follow symlinks when creating code packages\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/958"},"#958"),")")))),(0,i.kt)("h2",{id:"251-feb-15-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.5.1"},"2.5.1 (Feb 15, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.5.1 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"New Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Introduce Mamba as a dependency solver for ",(0,i.kt)("inlineCode",{parentName:"li"},"@conda")," in\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/918"},"#918")," . Mamba promises faster package\ndependency resolution times, which should result in an appreciable speedup in flow\nenvironment initialization. It is not yet enabled by default; to use it you need to\nset ",(0,i.kt)("inlineCode",{parentName:"li"},"METAFLOW_CONDA_DEPENDENCY_RESOLVER")," to ",(0,i.kt)("inlineCode",{parentName:"li"},"mamba")," in Metaflow config. "))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Improvements"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Vendor in ",(0,i.kt)("a",{parentName:"li",href:"https://click.palletsprojects.com/en/8.0.x/"},"click")," to reduce chances of\ndependency conflicts with user code in\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/929"},"#929"))))),(0,i.kt)("h2",{id:"250-jan-25-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.5.0"},"2.5.0 (Jan 25, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.5.0 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"New Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"\u2728 Metaflow cards are now publicly available! For details, see a new section\nin the documentation, ",(0,i.kt)("a",{parentName:"li",href:"https://docs.metaflow.org/metaflow/visualizing-results"},"Visualizing\nResults"),", and a ",(0,i.kt)("a",{parentName:"li",href:"https://outerbounds.com/blog/integrating-pythonic-visual-reports-into-ml-pipelines/"},"release\nblog\npost"),"."))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix issue in Step Functions integration with CLI defined decorators (\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/920"},"#920")," )"),(0,i.kt)("li",{parentName:"ul"},"Fix compute_resources to take into account string values (\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/919"},"#919")," )")))),(0,i.kt)("h2",{id:"249-jan-18-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.4.9"},"2.4.9 (Jan 18, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.4.9 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Improvements",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Store information about the DAG being executed in an artifact. This will allow to\nrender execution DAG in a ",(0,i.kt)("inlineCode",{parentName:"li"},"@card")," (\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/822"},"#822")," )"))),(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fixed cli command when task_id provided (\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/890"},"#890")," )"),(0,i.kt)("li",{parentName:"ul"},"Fix with metadata syncing on AWS Batch when running without remote metadata service\n( ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/902"},"#902")," )"),(0,i.kt)("li",{parentName:"ul"},"Fix default resource math. Previously we sometimes computed vCPU and memory settings\nincorrectly, in cases when they were set to something less than the default value (\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/810"},"#810")," , fixes\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/467"},"#467")," )")))),(0,i.kt)("h2",{id:"248-jan-10-2022"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.4.8"},"2.4.8 (Jan 10, 2022)")),(0,i.kt)("p",null,"The Metaflow 2.4.8 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Improvements",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Improved validation logic to capture reserved keywords\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/830"},"#830"),", fixes\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/589"},"#589"),")"),(0,i.kt)("li",{parentName:"ul"},"Remove default use of repo.anaconda.com\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/832"},"#832"),")"))),(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws_retry"),"'s ",(0,i.kt)("inlineCode",{parentName:"li"},"S3_RETRY_COUNT")," now has to be >=1\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/876"},"#876"),")"),(0,i.kt)("li",{parentName:"ul"},"Fix argument type handling for host_volumes when used with --with and Step Functions\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/884"},"#884"),")")))),(0,i.kt)("h2",{id:"247-dec-16-2021"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.4.7"},"2.4.7 (Dec 16, 2021)")),(0,i.kt)("p",null,"The Metaflow 2.4.7 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Improvements",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Added plumbing for ",(0,i.kt)("inlineCode",{parentName:"li"},"@card")," decorator"),(0,i.kt)("li",{parentName:"ul"},"Added plumbing to support distributed training on GPUs")))),(0,i.kt)("h2",{id:"246-dec-16-2021"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.4.6"},"2.4.6 (Dec 16, 2021)")),(0,i.kt)("p",null,"This version was skipped due to technical reasons"),(0,i.kt)("h2",{id:"245-dec-8-2021"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.4.5"},"2.4.5 (Dec 8, 2021)")),(0,i.kt)("p",null,"The Metaflow 2.4.5 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Address an issue with load_artifacts\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/833"},"#833"),", fixes\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/819"},"#819"),")"),(0,i.kt)("li",{parentName:"ul"},"Fixed mflog stream redirection in Step Functions\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/851"},"#851"),")")))),(0,i.kt)("h2",{id:"244-nov-29-2021"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/2.4.4"},"2.4.4 (Nov 29, 2021)")),(0,i.kt)("p",null,"The Metaflow 2.4.4 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#user-content-v2.4.4_improvements"},"Improvements"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Add default image config option as described in\n",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/489"},"#489"),"\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/813"},"#813"),")"),(0,i.kt)("li",{parentName:"ul"},"Read default k8s namespace from config\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/823"},"#823"),")"))),(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fixed a couple of issues in S3 error handling\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/821"},"#821"),")"),(0,i.kt)("li",{parentName:"ul"},"Fixed an issue with load_artifacts when several artifacts have the same name\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/817"},"#817"),")"))),(0,i.kt)("li",{parentName:"ul"},"Misc internal improvements",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Pipe logs to $cwd/.logs instead of /logs for ",(0,i.kt)("inlineCode",{parentName:"li"},"@batch")," & ",(0,i.kt)("inlineCode",{parentName:"li"},"@kubernetes"),"\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/807"},"#807"),")"),(0,i.kt)("li",{parentName:"ul"},"mflog changes for supporting AWS Lambda\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/801"},"#801"),")"),(0,i.kt)("li",{parentName:"ul"},"Add 'last modified' to S3 object\n(",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/778"},"#778"),")")))),(0,i.kt)("h3",{id:"improvements-"},"Improvements ",(0,i.kt)("a",{href:"#user-content-v2.4.4_improvements",id:"user-content-v2.4.4_improvements"})),(0,i.kt)("h4",{id:"add-default-image-config-option-as-described-in-489-813"},"Add default image config option as described in ",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/issues/489"},"#489")," (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/813"},"#813"),")"),(0,i.kt)("p",null,"We're moving to a more consistent scheme for naming options related to docker images.\nYou can read the details in ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/489"},"#489"),", but\nthis release introduces new config options ",(0,i.kt)("inlineCode",{parentName:"p"},"DEFAULT_CONTAINER_IMAGE")," and\n",(0,i.kt)("inlineCode",{parentName:"p"},"DEFAULT_CONTAINER_REGISTRY")," that can be used to specify docker image in addition to\nplugin-specific options like ",(0,i.kt)("inlineCode",{parentName:"p"},"KUBERNETES_CONTAINER_IMAGE")),(0,i.kt)("h4",{id:"read-default-k8s-namespace-from-config-823"},"Read default k8s namespace from config (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/823"},"#823"),")"),(0,i.kt)("p",null,"This adds a new configuration option to set the default namespace for the Kubernetes\nplugin"),(0,i.kt)("h2",{id:"243-nov-3rd-2021"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.4.3"},"2.4.3 (Nov 3rd 2021)")),(0,i.kt)("p",null,"The Metaflow 2.4.3 release is a patch release"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#v2.4.2_bugs"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix a race condition when accessing artifacts of a running task"),(0,i.kt)("li",{parentName:"ul"},"Fix an issue when using a combination of ",(0,i.kt)("inlineCode",{parentName:"li"},"@catch")," and ",(0,i.kt)("inlineCode",{parentName:"li"},"@retry")," decorators"),(0,i.kt)("li",{parentName:"ul"},"Upgrade Pandas in tutorials"))),(0,i.kt)("li",{parentName:"ul"},"Miscellaneous",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"The code base has now been formatted with Black. PRs will automatically be formatted\nwhen submitted. If submitting PRs, you can also format your PRs using black (default\noptions) to avoid a reformatting PR.")))),(0,i.kt)("h3",{id:"bug-fixes-"},"Bug Fixes ",(0,i.kt)("a",{href:"#user-content-v2.4.3_bugs",id:"user-content-v2.4.3_bugs"})),(0,i.kt)("h4",{id:"fix-a-race-condition-when-accessing-artifacts-of-a-running-task-789-"},"Fix a race condition when accessing artifacts of a running task (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/789"},"#789"),") ",(0,i.kt)("a",{href:"#user-content-789",id:"user-content-789"})),(0,i.kt)("p",null,"When accessing artifacts of a running task using ",(0,i.kt)("inlineCode",{parentName:"p"},"Task(...).artifacts"),", a race condition\nexisted and the call could return a difficult to understand error message. This release\nfixes this issue and making this call will either return the artifacts present or no\nartifacts at all if none are present yet."),(0,i.kt)("h4",{id:"fix-an-issue-when-using-a-combination-of-catch-and-retry-decorators-776-"},"Fix an issue when using a combination of ",(0,i.kt)("inlineCode",{parentName:"h4"},"@catch")," and ",(0,i.kt)("inlineCode",{parentName:"h4"},"@retry")," decorators (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/776"},"#776"),") ",(0,i.kt)("a",{href:"#user-content-776",id:"user-content-776"})),(0,i.kt)("p",null,"A step as below:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"@retry(times=2)\n@catch(var='exception')\n@step\ndef my_step(self):\n    raise ValueError()\n")),(0,i.kt)("p",null,"would not retry 2 times as expected but instead the exception would be caught the first\ntime around. This release fixes this issue and the step will now execute a total of 3\ntimes and the exception will be caught on the third time."),(0,i.kt)("h4",{id:"upgrade-pandas-in-tutorials-707-"},"Upgrade Pandas in tutorials (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/707"},"#707"),") ",(0,i.kt)("a",{href:"#user-content-707",id:"user-content-707"})),(0,i.kt)("p",null,"On macOS Big Sur, certain tutorials were broken due to using an older version of Pandas.\nThis updates the tutorials to use 1.3.3 to solve this issue"),(0,i.kt)("h2",{id:"242-oct-25th-2021"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/2.4.2"},"2.4.2 (Oct 25th, 2021)")),(0,i.kt)("p",null,"The Metaflow 2.4.2 release is a patch release"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix a bug with accessing legacy logs through ",(0,i.kt)("inlineCode",{parentName:"li"},"metaflow.client")),(0,i.kt)("li",{parentName:"ul"},"Fix a bug with task datastore access when no task attempt has been recorded")))),(0,i.kt)("h3",{id:"bug-fixes"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-a-bug-with-accessing-legacy-logs-through-metaflowclient-779"},"Fix a bug with accessing legacy logs through ",(0,i.kt)("inlineCode",{parentName:"h4"},"metaflow.client")," (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/779"},"#779"),")"),(0,i.kt)("p",null,"Metaflow ",(0,i.kt)("inlineCode",{parentName:"p"},"v2.4.1")," introduced a bug (due to a typo) in accessing legacy task logs through\n",(0,i.kt)("inlineCode",{parentName:"p"},"metaflow.client")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'Task("pathspec/to/task").stdout\n')),(0,i.kt)("p",null,"This release fixes this issue."),(0,i.kt)("h4",{id:"fix-a-bug-with-task-datastore-access-when-no-task-attempt-has-been-recorded-780"},"Fix a bug with task datastore access when no task attempt has been recorded (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/780"},"#780"),")"),(0,i.kt)("p",null,"A subtle bug was introduced in Metaflow ",(0,i.kt)("inlineCode",{parentName:"p"},"2.4.0")," where the task datastore access fails\nwhen no task attempt was recorded. This release fixes this issue."),(0,i.kt)("h2",{id:"241-oct-18th-2021"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/2.4.1"},"2.4.1 (Oct 18th, 2021)")),(0,i.kt)("p",null,"The Metaflow 2.4.1 release is a patch release"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes-1"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Expose non-pythonic dependencies inside the conda environment on AWS Batch"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#new-features"},"New Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Introduce size properties for artifacts and logs in metaflow.client"),(0,i.kt)("li",{parentName:"ul"},"Expose attempt level task properties"),(0,i.kt)("li",{parentName:"ul"},"Introduce @kubernetes decorator for launching Metaflow tasks on Kubernetes")))),(0,i.kt)("h3",{id:"bug-fixes-1"},"Bug Fixes"),(0,i.kt)("h4",{id:"expose-non-pythonic-dependencies-inside-the-conda-environment-on-aws-batch-735"},"Expose non-pythonic dependencies inside the conda environment on AWS Batch (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/735"},"#735"),")"),(0,i.kt)("p",null,"Prior to this release, non-pythonic dependencies in a conda environment were not\nautomatically visible to a Metaflow task executing on AWS Batch (see\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/734"},"#734"),") (they were available for tasks\nthat were executed locally). For example"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'import os\nfrom metaflow import FlowSpec, step, conda, conda_base, batch\n\nclass TestFlow(FlowSpec):\n\n    @step\n    def start(self):\n        self.next(self.use_node)\n\n    @batch\n    @conda(libraries={"nodejs": ">=16.0.0"})\n    @step\n    def use_node(self):\n        print(os.system("node --version"))\n        self.next(self.end)\n\n    @step\n    def end(self):\n        pass\n\n\nif __name__ == "__main__":\n    TestFlow()\n')),(0,i.kt)("p",null,"would print an error. This release fixes the issue with the incorrect ",(0,i.kt)("inlineCode",{parentName:"p"},"PATH"),"\nconfiguration."),(0,i.kt)("h3",{id:"new-features"},"New Features"),(0,i.kt)("h4",{id:"introduce-size-properties-for-artifacts-and-logs-in-metaflowclient-752"},"Introduce size properties for artifacts and logs in metaflow.client (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/752"},"#752"),")"),(0,i.kt)("p",null,"This release exposes size properties for artifacts and logs (stderr and stdout) in\nmetaflow.client. These properties are relied upon by the Metaflow UI (",(0,i.kt)("a",{parentName:"p",href:"https://www.eventbrite.fi/e/netflix-data-science-metaflow-gui-pre-release-meetup-tickets-185523605097"},"open-sourcing\nsoon!"),")."),(0,i.kt)("h4",{id:"expose-attempt-level-task-properties-725"},"Expose attempt level task properties (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/725"},"#725"),")"),(0,i.kt)("p",null,"In addition to the above mentioned properties, now users of Metaflow can access attempt\nspecific Task metadata using the client"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Task('42/start/452', attempt=1)\n")),(0,i.kt)("h4",{id:"introduce-kubernetes-decorator-for-launching-metaflow-tasks-on-kubernetes-644"},"Introduce @kubernetes decorator for launching Metaflow tasks on Kubernetes (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/644"},"#644"),")"),(0,i.kt)("p",null,"This release marks the alpha launch of ",(0,i.kt)("inlineCode",{parentName:"p"},"@kubernetes")," decorator that allows farming off\nMetaflow tasks onto Kubernetes. The functionality works in exactly the same manner as\n",(0,i.kt)("a",{parentName:"p",href:"/scaling/remote-tasks/introduction"},(0,i.kt)("inlineCode",{parentName:"a"},"@batch"))," -"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from metaflow import FlowSpec, step, resources\n\nclass BigSum(FlowSpec):\n\n    @resources(memory=60000, cpu=1)\n    @step\n    def start(self):\n        import numpy\n        import time\n        big_matrix = numpy.random.ranf((80000, 80000))\n        t = time.time()\n        self.sum = numpy.sum(big_matrix)\n        self.took = time.time() - t\n        self.next(self.end)\n\n    @step\n    def end(self):\n        print("The sum is %f." % self.sum)\n        print("Computing it took %dms." % (self.took * 1000))\n\nif __name__ == \'__main__\':\n    BigSum()\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python big_sum.py run --with kubernetes\n")),(0,i.kt)("p",null,"will run all steps of this workflow on your existing EKS cluster (which can be\nconfigured with ",(0,i.kt)("inlineCode",{parentName:"p"},"metaflow configure eks"),") and provides all the goodness of Metaflow!"),(0,i.kt)("p",null,"To get started follow ",(0,i.kt)("a",{parentName:"p",href:"https://docs.google.com/document/d/1L_4Fws1KoGg_dtSTaRlAcREX1F8FPS4ZaYk7eJyu_jA/edit"},"this\nguide"),"!\nWe would appreciate your early feedback at\n",(0,i.kt)("a",{parentName:"p",href:"htps://slack.outerbounds.co"},"http://slack.outerbounds.co"),"."),(0,i.kt)("h2",{id:"240-oct-4th-2021"},(0,i.kt)("a",{parentName:"h2",href:"https://github.com/Netflix/metaflow/releases/tag/2.4.0"},"2.4.0 (Oct 4th, 2021)")),(0,i.kt)("p",null,"The Metaflow 2.4.0 release is a minor release and includes a ",(0,i.kt)("em",{parentName:"p"},"breaking change")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#breaking-changes"},"Breaking Changes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Change return type of created_at/finished_at in the client"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Better error messages in case of a Conda issue"),(0,i.kt)("li",{parentName:"ul"},"Fix error message in Metadata service"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#new-features"},"New Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"S3 retry counts are now configurable"),(0,i.kt)("li",{parentName:"ul"},"New datastore implementation resulting in improved performance"),(0,i.kt)("li",{parentName:"ul"},"S3 datatools performance improvements")))),(0,i.kt)("h3",{id:"breaking-changes"},"Breaking Changes"),(0,i.kt)("h4",{id:"change-return-type-of-created_atfinished_at-in-the-client-692"},"Change return type of created_at/finished_at in the client (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/692"},"#692"),")"),(0,i.kt)("p",null,"Prior to this release, the return type for ",(0,i.kt)("inlineCode",{parentName:"p"},"created_at")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"finished_at")," properties in\nthe Client API was a timestamp string. This release changes this to a ",(0,i.kt)("inlineCode",{parentName:"p"},"datetime")," object,\nas the old behavior is considered an unintentional mis-feature (see below for details)."),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"How to retain the old behavior")),(0,i.kt)("p",null,"To keep the old behavior, append an explicit string conversion,\n",(0,i.kt)("inlineCode",{parentName:"p"},".strftime('%Y-%m-%dT%H:%M:%SZ')"),", to the ",(0,i.kt)("inlineCode",{parentName:"p"},"created_at")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"finished_at")," calls, e.g."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"run.created_at.strftime('%Y-%m-%dT%H:%M:%SZ')\n")),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"Background")),(0,i.kt)("p",null,"The first versions of Metaflow (internal to Netflix) returned a ",(0,i.kt)("inlineCode",{parentName:"p"},"datetime")," object in all\ncalls dealing with timestamps in the Client API to make it easier to perform operations\nbetween timestamps. Unintentionally, the return type was changed to string in the\ninitial open-source release. This release introduces a number of internal changes,\nremoving all remaining discrepancies between the legacy version of Metaflow that was\nused inside Netflix and the open-source version."),(0,i.kt)("p",null,"The timestamp change is the only change affecting the user-facing API. While Metaflow\ncontinues to make a strong promise of backwards compatibility of user-facing features\nand APIs, the benefits of one-time unification outweigh the cost of this relatively\nminor breaking change."),(0,i.kt)("h3",{id:"bug-fixes-2"},"Bug Fixes"),(0,i.kt)("h4",{id:"better-error-messages-in-case-of-a-conda-issue-706"},"Better error messages in case of a Conda issue (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/706"},"#706"),")"),(0,i.kt)("p",null,"Conda errors printed to ",(0,i.kt)("inlineCode",{parentName:"p"},"stderr")," were not surfaced to the user; this release addresses\nthis issue."),(0,i.kt)("h4",{id:"fix-error-message-in-metadata-service-712"},"Fix error message in Metadata service (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/712"},"#712"),")"),(0,i.kt)("p",null,"The code responsible for printing error messages from the metadata service had a problem\nthat could cause it to be unable to print the correct error message and would instead\nraise another error that obfuscated the initial error. This release addresses this issue\nand errors from the metadata service are now properly printed."),(0,i.kt)("h3",{id:"new-features-1"},"New Features"),(0,i.kt)("h4",{id:"s3-retry-counts-are-now-configurable-700"},"S3 retry counts are now configurable (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/700"},"#700"),")"),(0,i.kt)("p",null,"This release allows you to set the number of times S3 access are retried (the default is\n7). The relevant environment variable is: ",(0,i.kt)("inlineCode",{parentName:"p"},"METAFLOW_S3_RETRY_COUNT"),"."),(0,i.kt)("h4",{id:"new-datastore-implementation-resulting-in-improved-performance-580"},"New datastore implementation resulting in improved performance (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/580"},"#580"),")"),(0,i.kt)("p",null,"The datastore implementation was reworked to make it easier to extend in the future. It\nalso now uploads artifacts in parallel to S3 (as opposed to sequentially) which can lead\nto better performance. The changes also contribute to a notable improvement in the speed\nof ",(0,i.kt)("inlineCode",{parentName:"p"},"resume")," which can now start resuming a flow twice as fast as before. Documentation\ncan be found ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/blob/master/docs/datastore.md"},"here"),"."),(0,i.kt)("h4",{id:"s3-datatools-performance-improvements-697"},"S3 datatools performance improvements (",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/pull/697"},"#697"),")"),(0,i.kt)("p",null,"The S3 datatools better handles small versus large files by using the ",(0,i.kt)("inlineCode",{parentName:"p"},"download_file"),"\ncommand for larger files and using ",(0,i.kt)("inlineCode",{parentName:"p"},"get_object")," for smaller files to minimize the number\nof calls made to S3."),(0,i.kt)("h2",{id:"236-sep-8th-2021"},"2.3.6 (Sep 8th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.3.6 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#2.3.6_bugs"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#673"},"Fix recursion error when ",(0,i.kt)("inlineCode",{parentName:"a"},"METAFLOW_DEFAULT_ENVIRONMENT")," is set to\n",(0,i.kt)("inlineCode",{parentName:"a"},"conda"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#676"},"Allow dots in ",(0,i.kt)("inlineCode",{parentName:"a"},"host_volumes")," attribute for ",(0,i.kt)("inlineCode",{parentName:"a"},"@batch"),"\ndecorator"))))),(0,i.kt)("h3",{id:"bug-fixes-3"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-recursion-error-when-metaflow_default_environment-is-set-to-conda"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases#673"},"Fix recursion error when ",(0,i.kt)("inlineCode",{parentName:"a"},"METAFLOW_DEFAULT_ENVIRONMENT")," is set to ",(0,i.kt)("inlineCode",{parentName:"a"},"conda"))),(0,i.kt)("p",null,"Prior to this release, setting default execution environment to ",(0,i.kt)("inlineCode",{parentName:"p"},"conda")," through\n",(0,i.kt)("inlineCode",{parentName:"p"},"METAFLOW_DEFAULT_ENVIRONMENT")," would result in a recursion error."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"METAFLOW_DEFAULT_ENVIRONMENT=conda python flow.py run\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'  File "/Users/savin/Code/metaflow/metaflow/cli.py", line 868, in start\n    if e.TYPE == environment][0](ctx.obj.flow)\n  File "/Users/savin/Code/metaflow/metaflow/plugins/conda/conda_environment.py", line 27, in __init__\n    if e.TYPE == DEFAULT_ENVIRONMENT][0](self.flow)\n  File "/Users/savin/Code/metaflow/metaflow/plugins/conda/conda_environment.py", line 27, in __init__\n    if e.TYPE == DEFAULT_ENVIRONMENT][0](self.flow)\n  File "/Users/savin/Code/metaflow/metaflow/plugins/conda/conda_environment.py", line 27, in __init__\n    if e.TYPE == DEFAULT_ENVIRONMENT][0](self.flow)\n  [Previous line repeated 488 more times]\n  File "/Users/savin/Code/metaflow/metaflow/plugins/conda/conda_environment.py", line 24, in __init__\n    from ...plugins import ENVIRONMENTS\nRecursionError: maximum recursion depth exceeded\n')),(0,i.kt)("p",null,"This release fixes this bug."),(0,i.kt)("h4",{id:"allow-dots-in-host_volumes-attribute-for-batch-decorator"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases#676"},"Allow dots in ",(0,i.kt)("inlineCode",{parentName:"a"},"host_volumes")," attribute for ",(0,i.kt)("inlineCode",{parentName:"a"},"@batch")," decorator")),(0,i.kt)("p",null,"Dots in volume names - ",(0,i.kt)("inlineCode",{parentName:"p"},"@batch(host_volumes='/path/with/.dot')")," weren't being sanitized\nproperly resulting in errors when a Metaflow task launched on AWS Batch. This release\nfixes this bug."),(0,i.kt)("h2",{id:"235-aug-23rd-2021"},"2.3.5 (Aug 23rd, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.3.5 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#features"},"Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/441"},"Enable mounting host volumes in AWS\nBatch")))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/651"},"Fix input values for Parameters of type ",(0,i.kt)("inlineCode",{parentName:"a"},"list")," within a Metaflow Foreach\ntask"))))),(0,i.kt)("h3",{id:"features"},"Features"),(0,i.kt)("h4",{id:"enable-mounting-host-volumes-in-aws-batch"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/issues/441"},"Enable mounting host volumes in AWS Batch")),(0,i.kt)("p",null,"With this release, you can now ",(0,i.kt)("a",{parentName:"p",href:"https://aws.amazon.com/premiumsupport/knowledge-center/batch-mount-efs/"},"mount and access instance host\nvolumes")," within\na Metaflow task running on AWS Batch. To access a host volume, you can add\n",(0,i.kt)("inlineCode",{parentName:"p"},"host-volumes")," argument to your ",(0,i.kt)("inlineCode",{parentName:"p"},"@batch")," decorator -"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"@batch(host_volumes=['/home', '/var/log'])\n")),(0,i.kt)("h3",{id:"bug-fixes-4"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-input-values-for-parameters-of-type-list-within-a-metaflow-foreach-task"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/issues/651"},"Fix input values for Parameters of type ",(0,i.kt)("inlineCode",{parentName:"a"},"list")," within a Metaflow Foreach task")),(0,i.kt)("p",null,"The following flow had a bug where the value for ",(0,i.kt)("inlineCode",{parentName:"p"},"self.input")," was being imputed to\n",(0,i.kt)("inlineCode",{parentName:"p"},"None")," rather than the dictionary element. This release fixes this issue -"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from metaflow import FlowSpec, Parameter, step, JSONType\n\nclass ForeachFlow(FlowSpec):\n    numbers_param = Parameter(\n        \"numbers_param\",\n        type=JSONType,\n        default='[1,2,3]'\n    )\n\n    @step\n    def start(self):\n        # This works, and passes each number to the run_number step:\n        #\n        # self.numbers = self.numbers_param\n        # self.next(self.run_number, foreach='numbers')\n\n        # But this doesn't:\n        self.next(self.run_number, foreach='numbers_param')\n\n    @step\n    def run_number(self):\n        print(f\"number is {self.input}\")\n        self.next(self.join)\n\n    @step\n    def join(self, inputs):\n        self.next(self.end)\n\n    @step\n    def end(self):\n        pass\n\nif __name__ == '__main__':\n    ForeachFlow()\n")),(0,i.kt)("h2",{id:"234-aug-11th-2021"},"2.3.4 (Aug 11th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.3.4 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes-1"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#637"},"Fix execution of ",(0,i.kt)("inlineCode",{parentName:"a"},"step-functions create")," when using an ",(0,i.kt)("inlineCode",{parentName:"a"},"IncludeFile"),"\nparameter"))))),(0,i.kt)("h3",{id:"bug-fixes-5"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-execution-of-step-functions-create-when-using-an-includefile-parameter"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases#637"},"Fix execution of ",(0,i.kt)("inlineCode",{parentName:"a"},"step-functions create")," when using an ",(0,i.kt)("inlineCode",{parentName:"a"},"IncludeFile")," parameter")),(0,i.kt)("p",null,"PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/607"},"#607")," in ",(0,i.kt)("inlineCode",{parentName:"p"},"Metaflow 2.3.3")," introduced a\nbug with ",(0,i.kt)("inlineCode",{parentName:"p"},"step-functions create")," command for ",(0,i.kt)("inlineCode",{parentName:"p"},"IncludeFile")," parameters. This release\nrolls back that PR. A subsequent release will reintroduce a modified version of PR\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/607"},"#607"),"."),(0,i.kt)("h2",{id:"233-jul-29th-2021"},"2.3.3 (Jul 29th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.3.3 release is a patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#features"},"Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#632"},"Support resource tags for Metaflow's integration with AWS\nBatch")))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#630"},"Properly handle ",(0,i.kt)("inlineCode",{parentName:"a"},"None")," as defaults for parameters for AWS Step Functions\nexecution")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#607"},"Fix return value of ",(0,i.kt)("inlineCode",{parentName:"a"},"IncludeFile"),"\nartifacts"))))),(0,i.kt)("h3",{id:"features-1"},"Features"),(0,i.kt)("h4",{id:"support-resource-tags-for-metaflows-integration-with-aws-batch"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases#632"},"Support resource tags for Metaflow's integration with AWS Batch")),(0,i.kt)("p",null,"Metaflow now supports setting ",(0,i.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/batch/latest/userguide/using-tags.html"},"resource tags for AWS Batch\njobs")," and\npropagating them to the underlying ECS tasks. The following tags are attached to the AWS\nBatch jobs now -"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"metaflow.flow_name")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"metaflow.run_id")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"metaflow.step_name")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"metaflow.user")," / ",(0,i.kt)("inlineCode",{parentName:"li"},"metaflow.owner")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"metaflow.version")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"metaflow.production_token"))),(0,i.kt)("p",null,"To enable this feature, set the environment variable (or alternatively in the ",(0,i.kt)("inlineCode",{parentName:"p"},"metaflow\nconfig"),") ",(0,i.kt)("inlineCode",{parentName:"p"},"METAFLOW_BATCH_EMIT_TAGS")," to ",(0,i.kt)("inlineCode",{parentName:"p"},"True"),". Keep in mind that the IAM role\n(",(0,i.kt)("inlineCode",{parentName:"p"},"MetaflowUserRole"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"StepFunctionsRole"),") submitting the jobs to AWS Batch will need to\nhave the ",(0,i.kt)("inlineCode",{parentName:"p"},"Batch:TagResource")," permission."),(0,i.kt)("h3",{id:"bug-fixes-6"},"Bug Fixes"),(0,i.kt)("h4",{id:"properly-handle-none-as-defaults-for-parameters-for-aws-step-functions-execution"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases#630"},"Properly handle ",(0,i.kt)("inlineCode",{parentName:"a"},"None")," as defaults for parameters for AWS Step Functions execution")),(0,i.kt)("p",null,"Prior to this release, a parameter specification like -"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'Parameter(name="test_param", type=int, default=None)\n')),(0,i.kt)("p",null,"will result in an error even though the default has been specified"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Flow failed:\n    The value of parameter test_param is ambiguous. It does not have a default and it is not required.\n")),(0,i.kt)("p",null,"This release fixes this behavior by allowing the flow to execute as it would locally."),(0,i.kt)("h4",{id:"fix-return-value-of-includefile-artifacts"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases#607"},"Fix return value of ",(0,i.kt)("inlineCode",{parentName:"a"},"IncludeFile")," artifacts")),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"IncludeFile")," parameter would return JSONified metadata about the file rather than\nthe file contents when accessed through the ",(0,i.kt)("inlineCode",{parentName:"p"},"Metaflow Client"),". This release fixes that\nbehavior by returning instead the file contents, just like any other Metaflow data\nartifact."),(0,i.kt)("h2",{id:"232-jun-29th-2021"},"2.3.2 (Jun 29th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.3.2 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"step-functions trigger")," command now supports ",(0,i.kt)("inlineCode",{parentName:"li"},"--run-id-file")," option")))),(0,i.kt)("h3",{id:"features-2"},"Features"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},(0,i.kt)("inlineCode",{parentName:"strong"},"step-functions trigger")," command now supports ",(0,i.kt)("inlineCode",{parentName:"strong"},"--run-id-file")," option")),(0,i.kt)("p",null,"Similar to ",(0,i.kt)("inlineCode",{parentName:"p"},"run")," , you can now pass ",(0,i.kt)("inlineCode",{parentName:"p"},"--run-id-file")," option to ",(0,i.kt)("inlineCode",{parentName:"p"},"step-function trigger"),".\nMetaflow then will write the triggered run id to the specified file. This is useful if\nyou have additional scripts that require the run id to examine the run or wait until it\nfinishes."),(0,i.kt)("h2",{id:"231-jun-23rd-2021"},"2.3.1 (Jun 23rd, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.3.1 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases/tag/2.3.1#556"},"Performance optimizations for\n",(0,i.kt)("inlineCode",{parentName:"a"},"merge_artifacts")))))),(0,i.kt)("h3",{id:"features-3"},"Features"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/releases/tag/2.3.1#556"},(0,i.kt)("strong",{parentName:"a"},"Performance optimizations for\n",(0,i.kt)("inlineCode",{parentName:"strong"},"merge_artifacts")))),(0,i.kt)("p",null,"Prior to this release, ",(0,i.kt)("inlineCode",{parentName:"p"},"FlowSpec.merge_artifacts")," was loading all of the merged\nartifacts into memory after doing all of the consistency checks with hashes. This\nrelease now avoids the memory and compute costs of decompressing, de-pickling,\nre-pickling, and recompressing each merged artifact - resulting in improved performance\nof ",(0,i.kt)("inlineCode",{parentName:"p"},"merge_artifacts"),"."),(0,i.kt)("h2",{id:"230-may-27th-2021"},"2.3.0 (May 27th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.3.0 release is a minor release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"../production/coordinating-larger-metaflow-projects"},"Coordinate larger Metaflow projects with\n",(0,i.kt)("inlineCode",{parentName:"a"},"@project"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#hyphenated-parameters-support-in-aws-step-functions"},"Hyphenated-parameters support in AWS Step\nFunctions")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#state-machine-execution-history-logging-for-aws-step-functions"},"State Machine execution history logging for AWS Step Functions in AWS CloudWatch\nLogs"))))),(0,i.kt)("h3",{id:"features-4"},"Features"),(0,i.kt)("h4",{id:"coordinate-larger-metaflow-projects-with-project"},(0,i.kt)("a",{parentName:"h4",href:"../production/coordinating-larger-metaflow-projects"},"Coordinate larger Metaflow projects with ",(0,i.kt)("inlineCode",{parentName:"a"},"@project"))),(0,i.kt)("p",null,"It's not uncommon for multiple people to work on the same workflow simultaneously.\nMetaflow makes it possible by keeping executions ",(0,i.kt)("a",{parentName:"p",href:"../scaling/tagging"},"isolated through independently stored\nartifacts and namespaces"),". However, by default, ",(0,i.kt)("a",{parentName:"p",href:"../production/scheduling-metaflow-flows/introduction"},"all AWS Step\nFunctions deployments")," are bound\nto the name of the workflow. If multiple people call ",(0,i.kt)("inlineCode",{parentName:"p"},"step-functions create"),"\nindependently, each deployment will overwrite the previous one. In the early stages of a\nproject, this simple model is convenient but as the project grows, it is desirable that\nmultiple people can test their own AWS Step Functions deployments without interference.\nOr, as a single developer, you may want to experiment with multiple independent AWS Step\nFunctions deployments of their workflow. This release introduces a ",(0,i.kt)("inlineCode",{parentName:"p"},"@project")," decorator\nto address this need. The ",(0,i.kt)("inlineCode",{parentName:"p"},"@project")," decorator is used at the ",(0,i.kt)("inlineCode",{parentName:"p"},"FlowSpec"),"-level to bind a\nFlow to a specific project. All flows with the same project name belong to the same\nproject."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from metaflow import FlowSpec, step, project, current\n\n@project(name='example_project')\nclass ProjectFlow(FlowSpec):\n\n    @step\n    def start(self):\n        print('project name:', current.project_name)\n        print('project branch:', current.branch_name)\n        print('is this a production run?', current.is_production)\n        self.next(self.end)\n\n    @step\n    def end(self):\n        pass\n\nif __name__ == '__main__':\n    ProjectFlow()\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python flow.py run\n")),(0,i.kt)("p",null,"The flow works exactly as before when executed outside AWS Step Functions and introduces\n",(0,i.kt)("inlineCode",{parentName:"p"},"project_name"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"branch_name")," & ",(0,i.kt)("inlineCode",{parentName:"p"},"is_production")," in the\n",(0,i.kt)("a",{parentName:"p",href:"../scaling/tagging#accessing-current-ids-in-a-flow"},(0,i.kt)("inlineCode",{parentName:"a"},"current"))," object."),(0,i.kt)("p",null,"On AWS Step Functions, however, ",(0,i.kt)("inlineCode",{parentName:"p"},"step-functions create")," will create a new workflow\n",(0,i.kt)("inlineCode",{parentName:"p"},"example_project.user.username.ProjectFlow")," (where ",(0,i.kt)("inlineCode",{parentName:"p"},"username")," is your username) with a\nuser-specific ",(0,i.kt)("a",{parentName:"p",href:"../scaling/tagging"},"isolated namespace")," and a ",(0,i.kt)("a",{parentName:"p",href:"../scaling/tagging#production-tokens"},"separate production\ntoken"),"."),(0,i.kt)("p",null,"For deploying experimental (test) versions that can run in parallel with production, you\ncan deploy custom branches with ",(0,i.kt)("inlineCode",{parentName:"p"},"--branch")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python flow.py --branch foo step-functions create\n")),(0,i.kt)("p",null,"To deploy a production version, you can deploy with ",(0,i.kt)("inlineCode",{parentName:"p"},"--production")," flag (or pair it up\nwith ",(0,i.kt)("inlineCode",{parentName:"p"},"--branch")," if you want to run multiple variants in production)"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python project_flow.py --production step-functions create\n")),(0,i.kt)("p",null,"Note that the isolated namespaces offered by ",(0,i.kt)("inlineCode",{parentName:"p"},"@project")," work best when your code is\ndesigned to respect these boundaries. For instance, when writing results to a table, you\ncan use current.branch_name to choose the table to write to or you can disable writes\noutside production by checking current.is_production."),(0,i.kt)("h4",{id:"hyphenated-parameters-support-in-aws-step-functions"},"Hyphenated-parameters support in AWS Step Functions"),(0,i.kt)("p",null,"Prior to this release, hyphenated parameters in AWS Step Functions weren't supported\nthrough CLI."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from metaflow import FlowSpec, Parameter, step\n\nclass ParameterFlow(FlowSpec):\n    foo_bar = Parameter('foo-bar',\n                      help='Learning rate',\n                      default=0.01)\n\n    @step\n    def start(self):\n        print('foo_bar is %f' % self.foo_bar)\n        self.next(self.end)\n\n    @step\n    def end(self):\n        print('foo_bar is still %f' % self.foo_bar)\n\nif __name__ == '__main__':\n    ParameterFlow()\n")),(0,i.kt)("p",null,"Now, users can create their flows as usual on AWS Step Functions (with ",(0,i.kt)("inlineCode",{parentName:"p"},"step-functions\ncreate"),") and trigger the deployed flows through CLI with hyphenated parameters -"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python flow.py step-functions trigger --foo-bar 42\n")),(0,i.kt)("h4",{id:"state-machine-execution-history-logging-for-aws-step-functions"},"State Machine execution history logging for AWS Step Functions"),(0,i.kt)("p",null,"Metaflow now logs ",(0,i.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/step-functions/latest/dg/cw-logs.html"},"State Machine execution history in AWS CloudWatch\nLogs")," for deployed\nMetaflow flows. You can enable it by specifying ",(0,i.kt)("inlineCode",{parentName:"p"},"--log-execution-history")," flag while\ncreating the state machine"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python flow.py step-functions create --log-execution-history\n")),(0,i.kt)("p",null,"Note that you would need to set the environment variable (or alternatively in your\nMetaflow config) ",(0,i.kt)("inlineCode",{parentName:"p"},"METAFLOW_SFN_EXECUTION_LOG_GROUP_ARN")," to your AWS CloudWatch Logs Log\nGroup ARN to pipe the execution history logs to AWS CloudWatch Logs"),(0,i.kt)("h2",{id:"2213-may-19th-2021"},"2.2.13 (May 19th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.2.13 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases/tag/2.2.13#534"},"Handle regression with ",(0,i.kt)("inlineCode",{parentName:"a"},"@batch")," execution on certain docker\nimages"))))),(0,i.kt)("h3",{id:"bug-fixes-7"},"Bug Fixes"),(0,i.kt)("h4",{id:"handle-regression-with-batch-execution-on-certain-docker-images"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases/tag/2.2.13#534"},"Handle regression with ",(0,i.kt)("inlineCode",{parentName:"a"},"@batch")," execution on certain docker images")),(0,i.kt)("p",null,"Certain ",(0,i.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html"},"docker\nimages"),"\noverride the entrypoint by executing ",(0,i.kt)("inlineCode",{parentName:"p"},"eval")," on the user-supplied command. The ",(0,i.kt)("inlineCode",{parentName:"p"},"2.2.10"),"\nrelease impacted these docker images where we modified the entrypoint to support\ndatastore based logging. This release fixes that regression."),(0,i.kt)("h2",{id:"2212-may-18th-2021"},"2.2.12 (May 18th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.2.12 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases/tag/2.2.12#532"},"Add capability to override AWS Step Functions state machine name while deploying\nflows to AWS Step\nFunctions")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases/tag/2.2.12#333"},"Introduce heartbeats for Metaflow\nflows")))),(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"[Handle regression with `Click",(0,i.kt)("blockquote",{parentName:"li"},(0,i.kt)("p",{parentName:"blockquote"},"=8.0.x`](",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/releases/tag/2.2.12#526"},"https://github.com/Netflix/metaflow/releases/tag/2.2.12#526"),")")))))),(0,i.kt)("h3",{id:"features-5"},"Features"),(0,i.kt)("h4",{id:"add-capability-to-override-aws-step-functions-state-machine-name-while-deploying-flows-to-aws-step-functions"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases/tag/2.2.12#532"},"Add capability to override AWS Step Functions state machine name while deploying flows to AWS Step Functions")),(0,i.kt)("p",null,"Prior to this release, the State Machines created by Metaflow while deploying flows to\nAWS Step Functions had the same name as that of the flow. With this release, Metaflow\nusers can now override the name of the State Machine created by passing in a ",(0,i.kt)("inlineCode",{parentName:"p"},"--name"),"\nargument : ",(0,i.kt)("inlineCode",{parentName:"p"},"python flow.py step-functions --name foo create")," or ",(0,i.kt)("inlineCode",{parentName:"p"},"python flow.py\nstep-functions --name foo trigger"),"."),(0,i.kt)("h4",{id:"introduce-heartbeats-for-metaflow-flows"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases/tag/2.2.12#333"},"Introduce heartbeats for Metaflow flows")),(0,i.kt)("p",null,"Metaflow now registers heartbeats at the run level and the task level for all flow\nexecutions (with the exception of flows running on AWS Step Functions where only\ntask-level heartbeats are captured). This provides the necessary metadata to ascertain\nif a run/task has been lost. Subsequent releases of Metaflow will expose this\ninformation through the client."),(0,i.kt)("h3",{id:"bug-fixes-8"},"Bug Fixes"),(0,i.kt)("h4",{id:"handle-regression-with-click-80x"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/releases/tag/2.2.12#526"},"Handle regression with ",(0,i.kt)("inlineCode",{parentName:"a"},"Click >=8.0.x"))),(0,i.kt)("p",null,"The latest release of Click (8.0.0) broke certain idempotency assumptions in Metaflow\nwhich PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/526"},"#526")," addresses."),(0,i.kt)("h2",{id:"2211-apr-30th-2021"},"2.2.11 (Apr 30th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.2.11 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix regression that broke compatibility with Python 2.7")))),(0,i.kt)("h3",{id:"bug-fixes-9"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-regression-that-broke-compatibility-with-python-27"},"Fix regression that broke compatibility with Python 2.7"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"shlex.quote"),", introduced in #493, is not compatible with Python 2.7. ",(0,i.kt)("inlineCode",{parentName:"p"},"pipes.quote")," is\nnow used for Python 2.7."),(0,i.kt)("h2",{id:"2210-apr-22nd-2021"},"2.2.10 (Apr 22nd, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.2.10 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"AWS Logs Group, Region and Stream are now available in metadata for tasks executed\non AWS Batch"),(0,i.kt)("li",{parentName:"ul"},"Execution logs are now available for all tasks in Metaflow universe"))),(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix regression with ",(0,i.kt)("inlineCode",{parentName:"li"},"ping/")," endpoint for Metadata service"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://gitter.im/metaflow_org/community?at=605decca68921b62f48a4190"},"Fix the behaviour of ",(0,i.kt)("inlineCode",{parentName:"a"},"--namespace=")," CLI args when executing a\nflow"))))),(0,i.kt)("h3",{id:"features-6"},"Features"),(0,i.kt)("h4",{id:"aws-logs-group-region-and-stream-are-now-available-in-metadata-for-tasks-executed-on-aws-batch"},"AWS Logs Group, Region and Stream are now available in metadata for tasks executed on AWS Batch"),(0,i.kt)("p",null,"For tasks that execute on AWS Batch, Metaflow now records the location where the AWS\nBatch instance writes the container logs in AWS Logs. This can be handy in locating the\nlogs through the client API -"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Step('Flow/42/a').task.metadata_dict['aws-batch-awslogs-group']\nStep('Flow/42/a').task.metadata_dict['aws-batch-awslogs-region']\nStep('Flow/42/a').task.metadata_dict['aws-batch-awslogs-stream']\n")),(0,i.kt)("h4",{id:"execution-logs-are-now-available-for-all-tasks-in-metaflow-universe"},"Execution logs are now available for all tasks in Metaflow universe"),(0,i.kt)("p",null,"All Metaflow runtime/task logs are now published via a sidecar process to the datastore.\nThe user-visible logs on the console are streamed directly from the datastore. For\nMetaflow's integrations with the cloud (AWS at the moment), the compute tasks logs (AWS\nBatch) are directly written by Metaflow into the datastore (Amazon S3) independent of\nwhere the flow is launched from (User's laptop or AWS Step Functions). This has multiple\nbenefits"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Metaflow no longer relies on AWS Cloud Watch for fetching the AWS Batch execution logs\nto the console - AWS Cloud Watch has rather low global API limits which have caused\nmultiple issues in the past for our users"),(0,i.kt)("li",{parentName:"ul"},"Logs for AWS Step Functions executions are now also available in Amazon S3 and can be\neasily fetched by simply doing ",(0,i.kt)("inlineCode",{parentName:"li"},"python flow.py logs 42/start")," or\n",(0,i.kt)("inlineCode",{parentName:"li"},"Step('Flow/42/start').task.stdout"),".")),(0,i.kt)("h3",{id:"bug-fixes-10"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-regression-with-ping-endpoint-for-metadata-service"},"Fix regression with ",(0,i.kt)("inlineCode",{parentName:"h4"},"ping/")," endpoint for Metadata service"),(0,i.kt)("p",null,"Fix a regression introduced in ",(0,i.kt)("inlineCode",{parentName:"p"},"v2.2.9")," where the endpoint responsible for ascertaining\nthe version of the deployed Metadata service was erroneously moved to ",(0,i.kt)("inlineCode",{parentName:"p"},"ping/")," from\n",(0,i.kt)("inlineCode",{parentName:"p"},"ping")),(0,i.kt)("h4",{id:"fix-the-behaviour-of---namespace-cli-args-when-executing-a-flow"},(0,i.kt)("a",{parentName:"h4",href:"https://gitter.im/metaflow_org/community?at=605decca68921b62f48a4190"},"Fix the behaviour of ",(0,i.kt)("inlineCode",{parentName:"a"},"--namespace=")," CLI args when executing a flow")),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"python flow.py run --namespace=")," now correctly makes the global namespace visible\nwithin the flow execution."),(0,i.kt)("h2",{id:"229-apr-19th-2021"},"2.2.9 (Apr 19th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.2.9 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://gitter.im/metaflow_org/community?at=60622af8940f1d555e277c12"},"Remove pinned pylint\ndependency")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://gitter.im/metaflow_org/community?at=5f80e21d02e81701b0106c6d"},"Improve handling of ",(0,i.kt)("inlineCode",{parentName:"a"},"/")," in image parameter for\nbatch")),(0,i.kt)("li",{parentName:"ul"},"List custom FlowSpec parameters in the intended order")))),(0,i.kt)("h3",{id:"bugs"},"Bugs"),(0,i.kt)("h4",{id:"remove-pinned-pylint-dependency"},(0,i.kt)("a",{parentName:"h4",href:"https://gitter.im/metaflow_org/community?at=60622af8940f1d555e277c12"},"Remove pinned pylint dependency")),(0,i.kt)("p",null,"Pylint dependency was unpinned and made floating. See PR\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/462"},"#462"),"."),(0,i.kt)("h4",{id:"improve-handling-of--in-image-parameter-for-batch"},(0,i.kt)("a",{parentName:"h4",href:"https://gitter.im/metaflow_org/community?at=5f80e21d02e81701b0106c6d"},"Improve handling of ",(0,i.kt)("inlineCode",{parentName:"a"},"/")," in image parameter for batch")),(0,i.kt)("p",null,"You are now able to specify docker images of the form ",(0,i.kt)("inlineCode",{parentName:"p"},"foo/bar/baz:tag")," in the batch\ndecorator. See PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/466"},"#466"),"."),(0,i.kt)("h4",{id:"list-custom-flowspec-parameters-in-the-intended-order"},"List custom FlowSpec parameters in the intended order"),(0,i.kt)("p",null,"The order in which parameters are specified by the user in the FlowSpec is now preserved\nwhen displaying them with ",(0,i.kt)("inlineCode",{parentName:"p"},"--help"),". See PR\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/456"},"#456"),"."),(0,i.kt)("h2",{id:"228-mar-15th-2021"},"2.2.8 (Mar 15th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.2.8 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://gitter.im/metaflow_org/community?at=604a2bfb44f5a454a46cc7f8"},"Fix ",(0,i.kt)("inlineCode",{parentName:"a"},"@environment")," behavior for conflicting attribute\nvalues")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://gitter.im/metaflow_org/community?at=6048a07d823b6654d296d62d"},"Fix ",(0,i.kt)("inlineCode",{parentName:"a"},"environment is not callable")," error when using\n",(0,i.kt)("inlineCode",{parentName:"a"},"@environment")))))),(0,i.kt)("h3",{id:"bugs-1"},"Bugs"),(0,i.kt)("h4",{id:"fix-environment-behavior-for-conflicting-attribute-values"},(0,i.kt)("a",{parentName:"h4",href:"https://gitter.im/metaflow_org/community?at=604a2bfb44f5a454a46cc7f8"},"Fix ",(0,i.kt)("inlineCode",{parentName:"a"},"@environment")," behavior for conflicting attribute values")),(0,i.kt)("p",null,"Metaflow was incorrectly handling environment variables passed through the\n",(0,i.kt)("inlineCode",{parentName:"p"},"@environment")," decorator in some specific instances. When ",(0,i.kt)("inlineCode",{parentName:"p"},"@environment")," decorator is\nspecified over multiple steps, the actual environment that's available to any step is\nthe union of attributes of all the ",(0,i.kt)("inlineCode",{parentName:"p"},"@environment")," decorators; which is incorrect\nbehavior. For example, in the following workflow -"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from metaflow import FlowSpec, step, batch, environment\nimport os\nclass LinearFlow(FlowSpec):\n    @environment(vars={'var':os.getenv('var_1')})\n    @step\n    def start(self):\n        print(os.getenv('var'))\n        self.next(self.a)\n    @environment(vars={'var':os.getenv('var_2')})\n    @step\n    def a(self):\n        print(os.getenv('var'))\n        self.next(self.end)\n    @step\n    def end(self):\n        pass\nif __name__ == '__main__':\n    LinearFlow()\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"var_1=foo var_2=bar python flow.py run\n")),(0,i.kt)("p",null,"will result in"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"Metaflow 2.2.7.post10+gitb7d4c48 executing LinearFlow for user:savin\nValidating your flow...\n    The graph looks good!\nRunning pylint...\n    Pylint is happy!\n2021-03-12 20:46:04.161 Workflow starting (run-id 6810):\n2021-03-12 20:46:04.614 [6810/start/86638 (pid 10997)] Task is starting.\n2021-03-12 20:46:06.783 [6810/start/86638 (pid 10997)] foo\n2021-03-12 20:46:07.815 [6810/start/86638 (pid 10997)] Task finished successfully.\n2021-03-12 20:46:08.390 [6810/a/86639 (pid 11003)] Task is starting.\n2021-03-12 20:46:10.649 [6810/a/86639 (pid 11003)] foo\n2021-03-12 20:46:11.550 [6810/a/86639 (pid 11003)] Task finished successfully.\n2021-03-12 20:46:12.145 [6810/end/86640 (pid 11009)] Task is starting.\n2021-03-12 20:46:15.382 [6810/end/86640 (pid 11009)] Task finished successfully.\n2021-03-12 20:46:15.563 Done!\n")),(0,i.kt)("p",null,"Note the output for the step ",(0,i.kt)("inlineCode",{parentName:"p"},"a")," which should have been ",(0,i.kt)("inlineCode",{parentName:"p"},"bar"),". PR\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/452"},"#452")," fixes the issue."),(0,i.kt)("h4",{id:"fix-environment-is-not-callable-error-when-using-environment"},(0,i.kt)("a",{parentName:"h4",href:"https://gitter.im/metaflow_org/community?at=6048a07d823b6654d296d62d"},"Fix ",(0,i.kt)("inlineCode",{parentName:"a"},"environment is not callable")," error when using ",(0,i.kt)("inlineCode",{parentName:"a"},"@environment"))),(0,i.kt)("p",null,"Using ",(0,i.kt)("inlineCode",{parentName:"p"},"@environment")," would often result in an error from ",(0,i.kt)("inlineCode",{parentName:"p"},"pylint")," - ",(0,i.kt)("inlineCode",{parentName:"p"},"E1102: environment\nis not callable (not-callable)"),". Users were getting around this issue by launching their\nflows with ",(0,i.kt)("inlineCode",{parentName:"p"},"--no-pylint"),". PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/451"},"#451")," fixes\nthis issue."),(0,i.kt)("h2",{id:"227-feb-8th-2021"},"2.2.7 (Feb 8th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.2.7 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/releases#2.2.7_bugs"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://gitter.im/metaflow_org/community?at=601f56d955359c58bf28ef1a"},"Handle for-eaches properly for AWS Step Functions workflows running on AWS\nFargate"))))),(0,i.kt)("h3",{id:"bugs-2"},"Bugs"),(0,i.kt)("h4",{id:"handle-for-eaches-properly-for-aws-step-functions-workflows-running-on-aws-fargate"},(0,i.kt)("a",{parentName:"h4",href:"https://gitter.im/metaflow_org/community?at=601f56d955359c58bf28ef1a"},"Handle for-eaches properly for AWS Step Functions workflows running on AWS Fargate")),(0,i.kt)("p",null,"Workflows orchestrated by AWS Step Functions were failing to properly execute ",(0,i.kt)("inlineCode",{parentName:"p"},"for-each"),"\nsteps on AWS Fargate. The culprit was lack of access to instance metadata for ECS.\nMetaflow instantiates a connection to Amazon DynamoDB to keep track of ",(0,i.kt)("inlineCode",{parentName:"p"},"for-each"),"\ncardinality. This connection requires knowledge of the region that the job executes in\nand is made available via ",(0,i.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html"},"instance\nmetadata"),"\non EC2; which unfortunately is not available on ECS (for AWS Fargate). This fix\nintroduces the necessary checks for inferring the region correctly for tasks executing\non AWS Fargate. Note that after the recent changes to ",(0,i.kt)("a",{parentName:"p",href:"https://aws.amazon.com/blogs/aws/amazon-s3-update-strong-read-after-write-consistency/"},"Amazon S3's consistency\nmodel"),",\nthe Amazon DynamoDB dependency is no longer needed and will be done away in a subsequent\nrelease. PR: ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/436"},"#436")),(0,i.kt)("h2",{id:"226-jan-26th-2021"},"2.2.6 (Jan 26th, 2021)"),(0,i.kt)("p",null,"The Metaflow 2.2.6 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Support AWS Fargate as compute backend for Metaflow tasks launched on AWS Batch"),(0,i.kt)("li",{parentName:"ul"},"Support ",(0,i.kt)("inlineCode",{parentName:"li"},"shared_memory"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"max_swap"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"swappiness")," attributes for Metaflow tasks\nlaunched on AWS Batch"),(0,i.kt)("li",{parentName:"ul"},"Support wider very-wide workflows on top of AWS Step Functions"))),(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Assign tags to ",(0,i.kt)("inlineCode",{parentName:"li"},"Run")," objects generated through AWS Step Functions executions"),(0,i.kt)("li",{parentName:"ul"},"Pipe all workflow set-up logs to ",(0,i.kt)("inlineCode",{parentName:"li"},"stderr")),(0,i.kt)("li",{parentName:"ul"},"Handle null assignment to ",(0,i.kt)("inlineCode",{parentName:"li"},"IncludeFile")," properly")))),(0,i.kt)("h3",{id:"features-7"},"Features"),(0,i.kt)("h4",{id:"support-aws-fargate-as-compute-backend-for-metaflow-tasks-launched-on-aws-batch"},"Support AWS Fargate as compute backend for Metaflow tasks launched on AWS Batch"),(0,i.kt)("p",null,"At ",(0,i.kt)("a",{parentName:"p",href:"https://aws.amazon.com/blogs/aws/new-fully-serverless-batch-computing-with-aws-batch-support-for-aws-fargate/"},"AWS re:invent 2020, AWS announced support for AWS\nFargate"),"\nas a compute backend (in addition to EC2) for AWS Batch. With this feature, Metaflow\nusers can now submit their Metaflow jobs to AWS Batch Job Queues which are connected to\nAWS Fargate Compute Environments as well. By setting the environment variable -\n",(0,i.kt)("inlineCode",{parentName:"p"},"METAFLOW_ECS_FARGATE_EXECUTION_ROLE"),", users can configure the ecsTaskExecutionRole for\nthe AWS Batch container and AWS Fargate agent."),(0,i.kt)("h4",{id:"support-shared_memory-max_swap-swappiness-attributes-for-metaflow-tasks-launched-on-aws-batch"},"Support ",(0,i.kt)("inlineCode",{parentName:"h4"},"shared_memory"),", ",(0,i.kt)("inlineCode",{parentName:"h4"},"max_swap"),", ",(0,i.kt)("inlineCode",{parentName:"h4"},"swappiness")," attributes for Metaflow tasks launched on AWS Batch"),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"@batch")," decorator now supports ",(0,i.kt)("inlineCode",{parentName:"p"},"shared_memory"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"max_swap"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"swappiness")," attributes\nfor Metaflow tasks launched on AWS Batch to provide a greater degree of control for\nmemory management."),(0,i.kt)("h4",{id:"support-wider-very-wide-workflows-on-top-of-aws-step-functions"},"Support wider very-wide workflows on top of AWS Step Functions"),(0,i.kt)("p",null,"The tag ",(0,i.kt)("inlineCode",{parentName:"p"},"metaflow_version:")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"runtime:")," is now available for all packaged executions\nand remote executions as well. This ensures that every run logged by Metaflow will have\n",(0,i.kt)("inlineCode",{parentName:"p"},"metaflow_version")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"runtime")," system tags available."),(0,i.kt)("h3",{id:"bug-fixes-11"},"Bug Fixes"),(0,i.kt)("h4",{id:"assign-tags-to-run-objects-generated-through-aws-step-functions-executions"},"Assign tags to ",(0,i.kt)("inlineCode",{parentName:"h4"},"Run")," objects generated through AWS Step Functions executions"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"Run")," objects generated by flows executed on top of AWS Step Functions were missing the\ntags assigned to the flow; even though the tags were correctly persisted to tasks. This\nrelease fixes and brings inline the tagging behavior as observed with local flow\nexecutions."),(0,i.kt)("h4",{id:"pipe-all-workflow-set-up-logs-to-stderr"},"Pipe all workflow set-up logs to ",(0,i.kt)("inlineCode",{parentName:"h4"},"stderr")),(0,i.kt)("p",null,"Execution set-up logs for ",(0,i.kt)("inlineCode",{parentName:"p"},"@conda")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"IncludeFile")," were being piped to ",(0,i.kt)("inlineCode",{parentName:"p"},"stdout")," which\nmade manipulating the output of commands like ",(0,i.kt)("inlineCode",{parentName:"p"},"python flow.py step-functions create\n--only-json")," a bit difficult. This release moves the workflow set-up logs to ",(0,i.kt)("inlineCode",{parentName:"p"},"stderr"),"."),(0,i.kt)("h4",{id:"handle-null-assignment-to-includefile-properly"},"Handle null assignment to ",(0,i.kt)("inlineCode",{parentName:"h4"},"IncludeFile")," properly"),(0,i.kt)("p",null,"A workflow executed without a required ",(0,i.kt)("inlineCode",{parentName:"p"},"IncludeFile")," parameter would fail when the\nparameter was referenced inside the flow. This release fixes the issue by assigning a\nnull value to the parameter in such cases."),(0,i.kt)("h2",{id:"225-nov-11th-2020"},"2.2.5 (Nov 11th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.2.5 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Log ",(0,i.kt)("inlineCode",{parentName:"li"},"metaflow_version:")," and ",(0,i.kt)("inlineCode",{parentName:"li"},"runtime:")," tag for all executions"))),(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Handle inconsistently cased file system issue when creating @conda environments on\nmacOS for linux-64")))),(0,i.kt)("h3",{id:"features-8"},"Features"),(0,i.kt)("h4",{id:"log-metaflow_version-and-runtime-tag-for-all-executions"},"Log ",(0,i.kt)("inlineCode",{parentName:"h4"},"metaflow_version:")," and ",(0,i.kt)("inlineCode",{parentName:"h4"},"runtime:")," tag for all executions"),(0,i.kt)("p",null,"The tag ",(0,i.kt)("inlineCode",{parentName:"p"},"metaflow_version:")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"runtime:")," is now available for all packaged executions\nand remote executions as well. This ensures that every run logged by Metaflow will have\n",(0,i.kt)("inlineCode",{parentName:"p"},"metaflow_version")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"runtime")," system tags available."),(0,i.kt)("h3",{id:"bug-fixes-12"},"Bug Fixes"),(0,i.kt)("h4",{id:"handle-inconsistently-cased-file-system-issue-when-creating-conda-environments-on-macos-for-linux-64"},"Handle inconsistently cased file system issue when creating @conda environments on macOS for linux-64"),(0,i.kt)("p",null,"Conda fails to correctly set up environments for linux-64 packages on macOS at times due\nto inconsistently cased filesystems. Environment creation is needed to collect the\nnecessary metadata for correctly setting up the conda environment on AWS Batch. This fix\nsimply ignores the error-checks that conda throws while setting up the environments on\nmacOS when the intended destination is AWS Batch."),(0,i.kt)("h2",{id:"224-oct-28th-2020"},"2.2.4 (Oct 28th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.2.4 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Features",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Metaflow is now compliant with AWS GovCloud & AWS CN regions"))),(0,i.kt)("li",{parentName:"ul"},"Bug Fixes",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Address a bug with overriding the default value for\n",(0,i.kt)("a",{parentName:"li",href:"../scaling/data#data-in-local-files"},"IncludeFile")),(0,i.kt)("li",{parentName:"ul"},"Port AWS region check for AWS DynamoDb from ",(0,i.kt)("inlineCode",{parentName:"li"},"curl")," to ",(0,i.kt)("inlineCode",{parentName:"li"},"requests"))))),(0,i.kt)("h3",{id:"features-9"},"Features"),(0,i.kt)("h4",{id:"metaflow-is-now-compliant-with-aws-govcloud--aws-cn-regions"},"Metaflow is now compliant with AWS GovCloud & AWS CN regions"),(0,i.kt)("p",null,"AWS GovCloud & AWS CN users can now enjoy all the features of Metaflow within their\nregion partition with no change on their end. PR: #364"),(0,i.kt)("h3",{id:"bug-fixes-13"},"Bug Fixes"),(0,i.kt)("h4",{id:"address-a-bug-with-overriding-the-default-value-for-includefile"},"Address a bug with overriding the default value for ",(0,i.kt)("a",{parentName:"h4",href:"../scaling/data#data-in-local-files"},"IncludeFile")),(0,i.kt)("p",null,"Metaflow v2.1.0 introduced a bug in ",(0,i.kt)("a",{parentName:"p",href:"../scaling/data#data-in-local-files"},"IncludeFile\nfunctionality")," which prevented users from\noverriding the default value specified."),(0,i.kt)("h4",{id:"port-aws-region-check-for-aws-dynamodb-from-curl-to-requests"},"Port AWS region check for AWS DynamoDb from ",(0,i.kt)("inlineCode",{parentName:"h4"},"curl")," to ",(0,i.kt)("inlineCode",{parentName:"h4"},"requests")),(0,i.kt)("p",null,"Metaflow's AWS Step Functions' integration relies on AWS DynamoDb to manage\n",(0,i.kt)("a",{parentName:"p",href:"../metaflow/basics#foreach"},"foreach")," constructs. Metaflow was leveraging ",(0,i.kt)("inlineCode",{parentName:"p"},"curl")," at\nruntime to detect the region for AWS DynamoDb. Some docker images don't have ",(0,i.kt)("inlineCode",{parentName:"p"},"curl"),"\ninstalled by default; moving to ",(0,i.kt)("inlineCode",{parentName:"p"},"requests")," (a metaflow dependency) fixes the issue."),(0,i.kt)("h2",{id:"223-sept-8th-2020"},"2.2.3 (Sept 8th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.2.3 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix issue ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/305"},"#305")," : Default 'help'\nfor parameters was not handled properly."),(0,i.kt)("li",{parentName:"ul"},"Pin the conda library versions for Metaflow default dependencies based on the Python\nversion."),(0,i.kt)("li",{parentName:"ul"},"Add conda bin path to the PATH environment variable during Metaflow step execution."),(0,i.kt)("li",{parentName:"ul"},"Fix a typo in metaflow/debug.py")))),(0,i.kt)("h3",{id:"bug-fixes-14"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-issue-305--default-help-for-parameters-was-not-handled-properly"},"Fix issue ",(0,i.kt)("a",{parentName:"h4",href:"https://github.com/Netflix/metaflow/issues/305"},"#305")," : Default 'help' for parameters was not handled properly"),(0,i.kt)("p",null,"Fix the issue where default ",(0,i.kt)("inlineCode",{parentName:"p"},"help")," for parameters was not handled properly. Issue\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/305"},"#305"),": flow fails because\n",(0,i.kt)("inlineCode",{parentName:"p"},"IncludeFile"),"'s default value for the ",(0,i.kt)("inlineCode",{parentName:"p"},"help")," argument is None. PR:\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/318"},"#318")),(0,i.kt)("h4",{id:"pin-the-conda-library-versions-for-metaflow-default-dependencies-based-on-the-python-version"},"Pin the conda library versions for Metaflow default dependencies based on the Python version"),(0,i.kt)("p",null,"The previously pinned library version does not work with python 3.8. Now we have two\nsets of different version combinations which should work for python 2.7, 3.5, 3.6, 3.7,\nand 3.8. PR: ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/308"},"#308")),(0,i.kt)("h4",{id:"add-conda-bin-path-to-the-path-environment-variable-during-metaflow-step-execution"},"Add conda bin path to the PATH environment variable during Metaflow step execution"),(0,i.kt)("p",null,"Previously the executable installed in conda environment was not visible inside Metaflow\nsteps. Fixing this issue by appending conda bin path to the PATH environment variable.\nPR: ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/307"},"#307")),(0,i.kt)("p",null,"PRs: ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/307"},"#307"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/308"},"#308"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/310"},"#310"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/314"},"#314"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/317"},"#317"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/318"},"#318")),(0,i.kt)("h2",{id:"222-aug-20th-2020"},"2.2.2 (Aug 20th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.2.2 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix a regression introduced in 2.2.1 related to Conda environments"),(0,i.kt)("li",{parentName:"ul"},"Clarify Pandas requirements for Tutorial Episode 04"),(0,i.kt)("li",{parentName:"ul"},"Fix an issue with the metadata service")))),(0,i.kt)("h3",{id:"bug-fixes-15"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-a-regression-with-conda"},"Fix a regression with Conda"),(0,i.kt)("p",null,"Metaflow 2.2.1 included a commit which was merged too early and broke the use of Conda.\nThis release reverses this patch."),(0,i.kt)("h4",{id:"clarify-pandas-version-needed-for-episode-04"},"Clarify Pandas version needed for Episode 04"),(0,i.kt)("p",null,"Recent versions of Pandas are not backward compatible with the one used in the tutorial;\na small comment was added to warn of this fact."),(0,i.kt)("h4",{id:"fix-an-issue-with-the-metadata-service"},"Fix an issue with the metadata service"),(0,i.kt)("p",null,"In some cases, the metadata service would not properly create runs or tasks."),(0,i.kt)("p",null,"PRs ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/296"},"#296"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/297"},"#297"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/298"},"#298")),(0,i.kt)("h2",{id:"221-aug-17th-2020"},"2.2.1 (Aug 17th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.2.1 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#features"},"Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Add ",(0,i.kt)("inlineCode",{parentName:"li"},"include")," parameter to ",(0,i.kt)("inlineCode",{parentName:"li"},"merge_artifacts"),"."))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix a regression introduced in 2.1 related to S3 datatools"),(0,i.kt)("li",{parentName:"ul"},"Fix an issue where Conda execution would fail if the Conda environment was not\nwriteable"),(0,i.kt)("li",{parentName:"ul"},"Fix the behavior of uploading artifacts to the S3 datastore in case of retries")))),(0,i.kt)("h3",{id:"features-10"},"Features"),(0,i.kt)("h4",{id:"add-include-parameter-for-merge_artifacts"},"Add ",(0,i.kt)("inlineCode",{parentName:"h4"},"include")," parameter for ",(0,i.kt)("inlineCode",{parentName:"h4"},"merge_artifacts")),(0,i.kt)("p",null,"You can now specify the artifacts to be merged explicitly by the ",(0,i.kt)("inlineCode",{parentName:"p"},"merge_artifacts"),"\nmethod as opposed to just specifying the ones that should ",(0,i.kt)("em",{parentName:"p"},"not")," be merged."),(0,i.kt)("h3",{id:"bug-fixes-16"},"Bug Fixes"),(0,i.kt)("h4",{id:"fix-a-regression-with-datatools"},"Fix a regression with datatools"),(0,i.kt)("p",null,"Fixes the regression described in\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/285"},"#285"),"."),(0,i.kt)("h4",{id:"fix-an-issue-with-conda-in-certain-environments"},"Fix an issue with Conda in certain environments"),(0,i.kt)("p",null,"In some cases, Conda is installed system wide and the user cannot write to its\ninstallation directory. This was causing issues when trying to use the Conda\nenvironment. Fixes ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/179"},"#179"),"."),(0,i.kt)("h4",{id:"fix-an-issue-with-the-s3-datastore-in-case-of-retries"},"Fix an issue with the S3 datastore in case of retries"),(0,i.kt)("p",null,"Retries were not properly handled when uploading artifacts to the S3 datastore. This fix\naddresses this issue."),(0,i.kt)("p",null,"PRs ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/282"},"#282"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/286"},"#286"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/287"},"#287"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/288"},"#288"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/289"},"#289"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/290"},"#290"),",\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/291"},"#291")),(0,i.kt)("h2",{id:"220-aug-4th-2020"},"2.2.0 (Aug 4th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.2.0 release is a minor release and introduces ",(0,i.kt)("a",{parentName:"p",href:"../../v/r/"},"Metaflow's support for R\nlang"),"."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#features-1"},"Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Support for R lang.")))),(0,i.kt)("h3",{id:"features-11"},"Features"),(0,i.kt)("h4",{id:"support-for-r-lang"},"Support for R lang."),(0,i.kt)("p",null,"This release provides an ",(0,i.kt)("a",{parentName:"p",href:"../../v/r/"},"idiomatic API to access Metaflow in R lang"),". It\npiggybacks on the Pythonic implementation as the backend providing most of the\nfunctionality previously accessible to the Python community. With this release, R users\ncan structure their code as a metaflow flow. Metaflow will ",(0,i.kt)("a",{parentName:"p",href:"../../v/r/metaflow/basics#the-structure-of-metaflow-code"},"snapshot the code, data, and\ndependencies")," automatically in\na content-addressed datastore allowing for ",(0,i.kt)("a",{parentName:"p",href:"../../v/r/metaflow/debugging#how-to-debug-failed-flows"},"resuming of\nworkflows"),", ",(0,i.kt)("a",{parentName:"p",href:"../../v/r/metaflow/client"},"reproducing past\nresults, and inspecting anything about the workflow")," e.g. in\na notebook or RStudio IDE. Additionally, without any changes to their workflows, users\ncan now ",(0,i.kt)("a",{parentName:"p",href:"../../v/r/metaflow/scaling"},"execute code on AWS Batch and interact with Amazon S3\nseamlessly"),"."),(0,i.kt)("p",null,"PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/263"},"#263")," and PR\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/214"},"#214")),(0,i.kt)("h2",{id:"211-jul-30th-2020"},"2.1.1 (Jul 30th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.1.1 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},"Bug Fixes"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Handle race condition for ",(0,i.kt)("inlineCode",{parentName:"li"},"/step")," endpoint of metadata service.")))),(0,i.kt)("h3",{id:"bug-fixes-17"},"Bug Fixes"),(0,i.kt)("h4",{id:"handle-race-condition-for-step-endpoint-of-metadata-service"},"Handle race condition for ",(0,i.kt)("inlineCode",{parentName:"h4"},"/step")," endpoint of metadata service."),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"foreach")," step in AWS Step Functions launches multiple AWS Batch tasks, each of\nwhich tries to register the step metadata if it already doesn't exist. This can result\nin a race condition and cause the task to fail. This patch properly handles the 409\nresponse from the service."),(0,i.kt)("p",null,"PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/258"},"#258")," & PR\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/260"},"#260")),(0,i.kt)("h2",{id:"210-jul-29th-2020"},"2.1.0 (Jul 29th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.1.0 release is a minor release and introduces ",(0,i.kt)("a",{parentName:"p",href:"../production/scheduling-metaflow-flows/introduction"},"Metaflow's integration\nwith AWS Step Functions"),"."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#features"},"Features"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Add capability to schedule Metaflow flows with AWS Step Functions."))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#improvements"},"Improvements"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix log indenting in Metaflow."),(0,i.kt)("li",{parentName:"ul"},"Throw exception properly if fetching code package from Amazon S3 on AWS Batch fails."),(0,i.kt)("li",{parentName:"ul"},"Remove millisecond information from timestamps returned by Metaflow client."),(0,i.kt)("li",{parentName:"ul"},"Handle CloudWatchLogs resource creation delay gracefully.")))),(0,i.kt)("h3",{id:"features-12"},"Features"),(0,i.kt)("h4",{id:"add-capability-to-schedule-metaflow-flows-with-aws-step-functions"},"Add capability to schedule Metaflow flows with AWS Step Functions."),(0,i.kt)("p",null,"Netflix uses an ",(0,i.kt)("a",{parentName:"p",href:"https://medium.com/@NetflixTechBlog/unbundling-data-science-workflows-with-metaflow-and-aws-step-functions-d454780c6280"},"internal DAG\nscheduler"),"\nto orchestrate most machine learning and ETL pipelines in production. Metaflow users at\nNetflix can seamlessly deploy and schedule their flows to this scheduler. Now, with this\nrelease, we are introducing a similar integration with ",(0,i.kt)("a",{parentName:"p",href:"https://aws.amazon.com/step-functions/"},"AWS Step\nFunctions")," where Metaflow users can ",(0,i.kt)("a",{parentName:"p",href:"../production/scheduling-metaflow-flows/introduction"},"easily\ndeploy & schedule their flows")," by\nsimply executing"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python myflow.py step-functions create\n")),(0,i.kt)("p",null,"which will create an AWS Step Functions state machine for them. With this feature,\nMetaflow users can now enjoy all the features of Metaflow along with a highly available,\nscalable, maintenance-free production scheduler without any changes in their existing\ncode."),(0,i.kt)("p",null,"We are also introducing a new decorator -\n",(0,i.kt)("a",{parentName:"p",href:"../production/scheduling-metaflow-flows/introduction#scheduling-a-flow"},(0,i.kt)("inlineCode",{parentName:"a"},"@schedule")),",\nwhich allows Metaflow users to instrument time-based triggers via ",(0,i.kt)("a",{parentName:"p",href:"https://aws.amazon.com/eventbridge/"},"Amazon\nEventBridge")," for their flows deployed on AWS Step\nFunctions."),(0,i.kt)("p",null,"With this integration, Metaflow users can ",(0,i.kt)("a",{parentName:"p",href:"../metaflow/client"},"inspect")," their flows\ndeployed on AWS Step Functions as before and ",(0,i.kt)("a",{parentName:"p",href:"../metaflow/debugging#reproducing-production-issues-locally"},"debug and\nreproduce")," results from AWS\nStep Functions on their local laptop or within a notebook."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"../production/scheduling-metaflow-flows/introduction"},"Documentation"),"\\\n",(0,i.kt)("a",{parentName:"p",href:"https://medium.com/@NetflixTechBlog/unbundling-data-science-workflows-with-metaflow-and-aws-step-functions-d454780c6280"},"Launch Blog\nPost")),(0,i.kt)("p",null,"PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/211"},"#211")," addresses Issue\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/2"},"#2"),"."),(0,i.kt)("h3",{id:"improvements"},"Improvements"),(0,i.kt)("h4",{id:"fix-log-indenting-in-metaflow"},"Fix log indenting in Metaflow."),(0,i.kt)("p",null,"Metaflow was inadvertently removing leading whitespace from user-visible logs on the\nconsole. Now Metaflow presents user-visible logs with the correct formatting."),(0,i.kt)("p",null,"PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/244"},"#244")," fixed issue\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/223"},"#223"),"."),(0,i.kt)("h4",{id:"throw-exception-properly-if-fetching-code-package-from-amazon-s3-on-aws-batch-fails"},"Throw exception properly if fetching code package from Amazon S3 on AWS Batch fails."),(0,i.kt)("p",null,"Due to malformed permissions, AWS Batch might not be able to fetch the code package from\nAmazon S3 for user code execution. In such scenarios, it wasn't apparent to the user,\nwhere the code package was being pulled from, making triaging any permission issue a bit\ndifficult. Now, the Amazon S3 file location is part of the exception stack trace."),(0,i.kt)("p",null,"PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/243"},"#243")," fixed issue\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/232"},"#232"),"."),(0,i.kt)("h4",{id:"remove-millisecond-information-from-timestamps-returned-by-metaflow-client"},"Remove millisecond information from timestamps returned by Metaflow client."),(0,i.kt)("p",null,"Metaflow uses ",(0,i.kt)("inlineCode",{parentName:"p"},"time")," to store the ",(0,i.kt)("inlineCode",{parentName:"p"},"created_at")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"finished_at")," information for the\n",(0,i.kt)("inlineCode",{parentName:"p"},"Run")," object returned by Metaflow client. ",(0,i.kt)("inlineCode",{parentName:"p"},"time")," unfortunately does not support the\n",(0,i.kt)("a",{parentName:"p",href:"https://docs.python.org/3/library/time.html#time.strftime"},(0,i.kt)("inlineCode",{parentName:"a"},"%f")," directive"),", making it\ndifficult to parse these fields by ",(0,i.kt)("inlineCode",{parentName:"p"},"datetime")," or ",(0,i.kt)("inlineCode",{parentName:"p"},"time"),". Since Metaflow doesn't expose\ntimings at millisecond grain, this PR drops the ",(0,i.kt)("inlineCode",{parentName:"p"},"%f")," directive."),(0,i.kt)("p",null,"PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/227"},"#227")," fixed issue\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/224"},"#224"),"."),(0,i.kt)("h4",{id:"handle-cloudwatchlogs-resource-creation-delay-gracefully"},"Handle CloudWatchLogs resource creation delay gracefully."),(0,i.kt)("p",null,"When launching jobs on AWS Batch, the CloudWatchLogStream might not be immediately\ncreated (and may never be created if say we fail to pull the docker image for any reason\nwhatsoever). Metaflow will now simply retry again next time."),(0,i.kt)("p",null,"PR ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/209"},"#209"),"."),(0,i.kt)("h2",{id:"205-apr-30th-2020"},"2.0.5 (Apr 30th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.0.5 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"*",(0,i.kt)("strong",{parentName:"li"},"*","["),"Improvements",(0,i.kt)("strong",{parentName:"li"},"](/internals/release-notes#2-0-5-improvements)","*","*"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Fix logging of prefixes in ",(0,i.kt)("inlineCode",{parentName:"li"},"datatools.S3._read_many_files"),"."),(0,i.kt)("li",{parentName:"ul"},"Increase retry count for AWS Batch logs streaming."),(0,i.kt)("li",{parentName:"ul"},"Upper-bound ",(0,i.kt)("inlineCode",{parentName:"li"},"pylint")," version to ",(0,i.kt)("inlineCode",{parentName:"li"},"< 2.5.0")," for compatibility issues.")))),(0,i.kt)("p",null,"The Metaflow 2.0.5 release is a minor patch release."),(0,i.kt)("h3",{id:"improvements--1"},"Improvements ",(0,i.kt)("a",{href:"#2-0-5-improvements",id:"2-0-5-improvements"})),(0,i.kt)("h4",{id:"fix-logging-of-prefixes-in-datatoolss3_read_many_files"},"Fix logging of prefixes in datatools.S3.","_","read_many_files"),(0,i.kt)("p",null,"Avoid a cryptic error message when ",(0,i.kt)("inlineCode",{parentName:"p"},"datatools.S3._read_many_files")," is unsuccessful by\nconverting ",(0,i.kt)("inlineCode",{parentName:"p"},"prefixes")," from a generator to a list."),(0,i.kt)("h4",{id:"increase-retry-count-for-aws-batch-logs-streaming"},"Increase retry count for AWS Batch logs streaming."),(0,i.kt)("p",null,"Modify the retry behavior for log fetching on AWS Batch by adding jitters to exponential\nbackoffs as well as reset the retry counter for every successful request."),(0,i.kt)("p",null,"Additionally, fail the Metaflow task when we fail to stream the task logs back to the\nuser's terminal even if AWS Batch task succeeds."),(0,i.kt)("h4",{id:"upper-bound-pylint-version-to--250"},"Upper-bound pylint version to < 2.5.0."),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"pylint")," version ",(0,i.kt)("inlineCode",{parentName:"p"},"2.5.0")," would mark Metaflow's ",(0,i.kt)("inlineCode",{parentName:"p"},"self.next()")," syntax as an error. As a\nresult, ",(0,i.kt)("inlineCode",{parentName:"p"},"python helloworld.py run")," would fail at the pylint check step unless we run\nwith ",(0,i.kt)("inlineCode",{parentName:"p"},"--no-pylint"),". This version upper-bound is supposed to automatically downgrade\n",(0,i.kt)("inlineCode",{parentName:"p"},"pylint")," during ",(0,i.kt)("inlineCode",{parentName:"p"},"metaflow")," installation if ",(0,i.kt)("inlineCode",{parentName:"p"},"pylint==2.5.0")," has been installed."),(0,i.kt)("h2",{id:"204-apr-28th-2020"},"2.0.4 (Apr 28th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.0.4 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"*",(0,i.kt)("strong",{parentName:"li"},"*","["),"Improvements",(0,i.kt)("strong",{parentName:"li"},"](release-notes#2-0-4-improvements)","*","*"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Expose ",(0,i.kt)("inlineCode",{parentName:"li"},"retry_count")," in\n",(0,i.kt)("a",{parentName:"li",href:"../scaling/tagging#accessing-current-ids-in-a-flow"},(0,i.kt)("inlineCode",{parentName:"a"},"Current"))),(0,i.kt)("li",{parentName:"ul"},"Mute superfluous ",(0,i.kt)("inlineCode",{parentName:"li"},"ThrottleExceptions")," in AWS Batch job logs"))),(0,i.kt)("li",{parentName:"ul"},"*",(0,i.kt)("strong",{parentName:"li"},"*","["),"Bug Fixes","*","*","](release-notes#2-0-4-bug-fixes)",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Set proper thresholds for retrying ",(0,i.kt)("inlineCode",{parentName:"li"},"DescribeJobs")," API for AWS Batch"),(0,i.kt)("li",{parentName:"ul"},"Explicitly override ",(0,i.kt)("inlineCode",{parentName:"li"},"PYTHONNOUSERSITE")," for ",(0,i.kt)("inlineCode",{parentName:"li"},"conda")," environments"),(0,i.kt)("li",{parentName:"ul"},"Preempt AWS Batch job log collection when the job fails to get into a ",(0,i.kt)("inlineCode",{parentName:"li"},"RUNNING"),"\nstate")))),(0,i.kt)("h3",{id:"improvements--2"},"Improvements ",(0,i.kt)("a",{href:"#2-0-4-improvements",id:"2-0-4-improvements"})),(0,i.kt)("h4",{id:"expose-retry_count-in-current"},"Expose ",(0,i.kt)("inlineCode",{parentName:"h4"},"retry_count")," in ",(0,i.kt)("inlineCode",{parentName:"h4"},"Current")),(0,i.kt)("p",null,"You can now use the ",(0,i.kt)("a",{parentName:"p",href:"../scaling/tagging#accessing-current-ids-in-a-flow"},(0,i.kt)("inlineCode",{parentName:"a"},"current")),"\nsingleton to access the ",(0,i.kt)("inlineCode",{parentName:"p"},"retry_count")," of your task. The first attempt of the task will\nhave ",(0,i.kt)("inlineCode",{parentName:"p"},"retry_count")," as 0 and subsequent retries will increment the ",(0,i.kt)("inlineCode",{parentName:"p"},"retry_count"),". As an\nexample:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'@retry\n@step\ndef my_step(self):\n    from metaflow import current\n    print("retry_count: %s" % current.retry_count)\n    self.next(self.a)\n')),(0,i.kt)("h4",{id:"mute-superfluous-throttleexceptions-in-aws-batch-job-logs"},"Mute superfluous ",(0,i.kt)("inlineCode",{parentName:"h4"},"ThrottleExceptions")," in AWS Batch job logs"),(0,i.kt)("p",null,"The AWS Logs API for ",(0,i.kt)("inlineCode",{parentName:"p"},"get_log_events")," has a global hard limit on 10 requests per sec.\nWhile we have retry logic in place to respect this limit, some of the\n",(0,i.kt)("inlineCode",{parentName:"p"},"ThrottleExceptions")," usually end up in the job logs causing confusion to the end-user.\nThis release addresses this issue (also documented in #184)."),(0,i.kt)("h3",{id:"bug-fixes--1"},"Bug Fixes ",(0,i.kt)("a",{href:"#2-0-4-bug-fixes",id:"2-0-4-bug-fixes"})),(0,i.kt)("h4",{id:"set-proper-thresholds-for-retrying-describejobs-api-for-aws-batch"},"Set proper thresholds for retrying ",(0,i.kt)("inlineCode",{parentName:"h4"},"DescribeJobs")," API for AWS Batch"),(0,i.kt)("p",null,"The AWS Batch API for ",(0,i.kt)("inlineCode",{parentName:"p"},"describe_jobs")," throws ",(0,i.kt)("inlineCode",{parentName:"p"},"ThrottleExceptions")," when managing a flow\nwith a very wide ",(0,i.kt)("inlineCode",{parentName:"p"},"for-each")," step. This release adds retry behavior with backoffs to add\nproper resiliency (addresses #138)."),(0,i.kt)("h4",{id:"explicitly-override-pythonnousersite-for-conda-environments"},"Explicitly override ",(0,i.kt)("inlineCode",{parentName:"h4"},"PYTHONNOUSERSITE")," for ",(0,i.kt)("inlineCode",{parentName:"h4"},"conda")," environments"),(0,i.kt)("p",null,"In certain user environments, to properly isolate ",(0,i.kt)("inlineCode",{parentName:"p"},"conda")," environments, we have to\nexplicitly override ",(0,i.kt)("inlineCode",{parentName:"p"},"PYTHONNOUSERSITE")," rather than simply relying on ",(0,i.kt)("inlineCode",{parentName:"p"},"python -s"),"\n(addresses #178)."),(0,i.kt)("h4",{id:"preempt-aws-batch-job-log-collection-when-the-job-fails-to-get-into-a-running-state"},"Preempt AWS Batch job log collection when the job fails to get into a ",(0,i.kt)("inlineCode",{parentName:"h4"},"RUNNING")," state"),(0,i.kt)("p",null,"Fixes a bug where if the AWS Batch job crashes before entering the ",(0,i.kt)("inlineCode",{parentName:"p"},"RUNNING")," state\n(often due to incorrect IAM perms), the previous log collection behavior would fail to\nprint the correct error message making it harder to debug the issue (addresses #185)."),(0,i.kt)("h2",{id:"203-mar-6th-2020"},"2.0.3 (Mar 6th, 2020)"),(0,i.kt)("p",null,"The Metaflow 2.0.3 release is a minor patch release."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"*",(0,i.kt)("strong",{parentName:"li"},"*","["),"Improvements",(0,i.kt)("strong",{parentName:"li"},"](/internals/release-notes#improvements)","*","*"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Parameter listing"),(0,i.kt)("li",{parentName:"ul"},"Ability to specify S3 endpoint"),(0,i.kt)("li",{parentName:"ul"},"Usability improvements"))),(0,i.kt)("li",{parentName:"ul"},"*",(0,i.kt)("strong",{parentName:"li"},"*","["),"Performance",(0,i.kt)("strong",{parentName:"li"},"](/internals/release-notes#performance)","*","*"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Conda"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/internals/release-notes#bug-fixes"},(0,i.kt)("strong",{parentName:"a"},"Bug Fixes")),"*","*","*","*",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Executing on AWS Batch")))),(0,i.kt)("h3",{id:"improvements-1"},"Improvements"),(0,i.kt)("h4",{id:"parameter-listing"},"Parameter listing"),(0,i.kt)("p",null,"You can now use the ",(0,i.kt)("inlineCode",{parentName:"p"},"current")," singleton (documented\n",(0,i.kt)("a",{parentName:"p",href:"../scaling/tagging#accessing-current-ids-in-a-flow"},"here"),") to access the names of the\nparameters passed into your flow. As an example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'for var in current.parameter_names:\n    print("Parameter %s has value %s" % (var, getattr(self, var))\n')),(0,i.kt)("p",null,"This addresses ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/137"},"#137"),"."),(0,i.kt)("h4",{id:"usability-improvements"},"Usability improvements"),(0,i.kt)("p",null,"A few issues were addressed to improve the usability of Metaflow. In particular, ",(0,i.kt)("inlineCode",{parentName:"p"},"show"),"\nnow properly respects indentation making the description of steps and flows more\nreadable. This addresses ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/issues/92"},"#92"),".\nSuperfluous print messages were also suppressed when executing on AWS batch with the\nlocal metadata provider (",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/152"},"#152"),")."),(0,i.kt)("h3",{id:"performance"},"Performance"),(0,i.kt)("h4",{id:"conda"},"Conda"),(0,i.kt)("p",null,"A smaller, newer and standalone Conda installer is now used resulting in faster and more\nreliable Conda bootstrapping (",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/123"},"#123"),")."),(0,i.kt)("h3",{id:"bug-fixes-18"},"Bug Fixes"),(0,i.kt)("h4",{id:"executing-on-aws-batch"},"Executing on AWS Batch"),(0,i.kt)("p",null,"We now check for the command line ",(0,i.kt)("inlineCode",{parentName:"p"},"--datastore-root")," prior to using the environment\nvariable ",(0,i.kt)("inlineCode",{parentName:"p"},"METAFLOW_DATASTORE_SYSROOT_S3")," when determining the S3 root\n(",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/134"},"#134"),"). This release also fixes an issue\nwhere using the local Metadata provider with AWS batch resulted in incorrect directory\nstructure in the ",(0,i.kt)("inlineCode",{parentName:"p"},".metaflow")," directory\n(",(0,i.kt)("a",{parentName:"p",href:"https://github.com/Netflix/metaflow/pull/141"},"#141"),")."),(0,i.kt)("h2",{id:"202-feb-11th-2020"},"2.0.2 (Feb 11th, 2020)"),(0,i.kt)("p",null,"Bug Fixes"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/107"},"Pin")," click to v7.0 or greater"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/118"},"Add")," checks to conda-package metadata\nto guard against .conda packages")),(0,i.kt)("h2",{id:"201-dec-16th-2019"},"2.0.1 (Dec 16th, 2019)"),(0,i.kt)("p",null,"Enhancements"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/53"},"Introduce")," ",(0,i.kt)("inlineCode",{parentName:"li"},"metaflow configure\n[import|export]")," for importing/exporting Metaflow configurations."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/59"},"Revamp")," ",(0,i.kt)("inlineCode",{parentName:"li"},"metaflow configure aws")," command\nto address usability ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/44"},"concerns"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/56"},"Handle")," keyboard interrupts for Batch\njobs ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/issues/54"},"more gracefully for large\nfan-outs"),".")),(0,i.kt)("p",null,"Bug Fixes"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Netflix/metaflow/pull/62"},"Fix")," a docker registry parsing bug in\nAWS Batch."),(0,i.kt)("li",{parentName:"ul"},"Fix various typos in Metaflow tutorials.")),(0,i.kt)("h2",{id:"200-dec-3rd-2019"},"2.0.0 (Dec 3rd, 2019)"),(0,i.kt)("h4",{id:"hello-world"},"Hello World!"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First Open Source Release."),(0,i.kt)("li",{parentName:"ul"},"Read the\n",(0,i.kt)("a",{parentName:"li",href:"https://medium.com/@NetflixTechBlog/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9"},"blogpost"),"\nannouncing the release")),(0,i.kt)("h2",{id:"releases-pre-200-were-internal-to-netflix"},"Releases pre-2.0.0 were internal to Netflix"))}m.isMDXComponent=!0}}]);