"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[1794],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>d});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),m=p(n),d=r,f=m["".concat(l,".").concat(d)]||m[d]||c[d]||o;return n?a.createElement(f,i(i({ref:t},u),{},{components:n})):a.createElement(f,i({ref:t},u))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var p=2;p<o;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2048:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var a=n(7462),r=(n(7294),n(3905));const o={},i="Using GPUs and Other Accelerators",s={unversionedId:"scaling/remote-tasks/gpu-compute",id:"scaling/remote-tasks/gpu-compute",title:"Using GPUs and Other Accelerators",description:"Metaflow enables access to hardware-accelerated computing, GPUs in particular, when",source:"@site/docs/scaling/remote-tasks/gpu-compute.md",sourceDirName:"scaling/remote-tasks",slug:"/scaling/remote-tasks/gpu-compute",permalink:"/scaling/remote-tasks/gpu-compute",draft:!1,editUrl:"https://github.dev/Netflix/metaflow-docs/blob/master/docs/scaling/remote-tasks/gpu-compute.md",tags:[],version:"current",frontMatter:{},sidebar:"python",previous:{title:"Controlling Parallelism",permalink:"/scaling/remote-tasks/controlling-parallelism"},next:{title:"Installing Drivers and Frameworks",permalink:"/scaling/remote-tasks/installing-drivers-and-frameworks"}},l={},p=[{value:"Using accelerators",id:"using-accelerators",level:2},{value:"GPUs",id:"gpus",level:3},{value:"Using AWS Trainium and Inferentia",id:"using-aws-trainium-and-inferentia",level:3},{value:"Using Google&#39;s Tensor Processing Units (TPUs)",id:"using-googles-tensor-processing-units-tpus",level:3},{value:"Monitoring GPU utilization",id:"monitoring-gpu-utilization",level:2}],u={toc:p};function c(e){let{components:t,...o}=e;return(0,r.kt)("wrapper",(0,a.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"using-gpus-and-other-accelerators"},"Using GPUs and Other Accelerators"),(0,r.kt)("p",null,"Metaflow enables access to hardware-accelerated computing, GPUs in particular, when\nusing ",(0,r.kt)("a",{parentName:"p",href:"aws-batch"},"AWS Batch")," or ",(0,r.kt)("a",{parentName:"p",href:"kubernetes"},"Kubernetes"),".\nYou can leverage"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Single accelerators - e.g. ",(0,r.kt)("inlineCode",{parentName:"li"},"@resources(gpu=1)")),(0,r.kt)("li",{parentName:"ul"},"Single instances with multiple accelerators - e.g. ",(0,r.kt)("inlineCode",{parentName:"li"},"@resources(gpu=4)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"distributed-computing"},"Multiple instances with multiple accelerators"))),(0,r.kt)("p",null,"You can find many examples of how to use Metaflow to fine-tune LLMs and\nother generative AI models, as well as how to train computer\nvision and other deep learning models ",(0,r.kt)("a",{parentName:"p",href:"https://outerbounds.com/blog/?category=Foundation%20Models"},"in these articles"),"."),(0,r.kt)("h2",{id:"using-accelerators"},"Using accelerators"),(0,r.kt)("p",null,"Before you can start taking advantage of hardware-accelerated steps, you need\nto take care of two prerequisites:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Add hardware-accelerated instances in ",(0,r.kt)("a",{parentName:"p",href:"/getting-started/infrastructure"},"your Metaflow stack"),".\nTake a look specific tips for ",(0,r.kt)("a",{parentName:"p",href:"aws-batch"},"AWS Batch")," and ",(0,r.kt)("a",{parentName:"p",href:"kubernetes"},"Kubernetes"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Configure your flow to ",(0,r.kt)("a",{parentName:"p",href:"installing-drivers-and-frameworks"},"include necessary drivers and frameworks"),"."))),(0,r.kt)("p",null,"After this, using the accelerators in straightforward as explained below."),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"Don't hesitate to reach out to ",(0,r.kt)("a",{parentName:"p",href:"http://chat.metaflow.org"},"Metaflow Slack")," if you need\nhelp get started!")),(0,r.kt)("h3",{id:"gpus"},"GPUs"),(0,r.kt)("p",null,"To use GPUs in your compute environment, use ",(0,r.kt)("a",{parentName:"p",href:"requesting-resources"},"the\n",(0,r.kt)("inlineCode",{parentName:"a"},"@resources")," decorator")," to get quick access to one or more GPUs\nlike in this example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from metaflow import FlowSpec, step, resources\n\nclass GPUFlow(FlowSpec):\n\n    @resources(memory=32000, cpu=4, gpu=1)\n    @step\n    def start(self):\n        from my_script import my_gpu_routine\n        my_gpu_routine()\n        self.next(self.end)\n\n    @step\n    def end(self):\n        pass\n\nif __name__ == '__main__':\n    GPUFlow()\n")),(0,r.kt)("p",null,"As usual with ",(0,r.kt)("inlineCode",{parentName:"p"},"@resources"),", the decorator is ignored for local runs. This allows you to\ndevelop the code locally, e.g. using GPU resources on your local workstation. To get access\nto the requested resources in the cloud, run the flow ",(0,r.kt)("inlineCode",{parentName:"p"},"--with kubernetes")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"--with batch"),"."),(0,r.kt)("p",null,"If you need more fine-grained control over what GPUs get used, use the decorators\nspecific to compute environment: For instance, ",(0,r.kt)("a",{parentName:"p",href:"/api/step-decorators/kubernetes"},(0,r.kt)("inlineCode",{parentName:"a"},"@kubernetes")," allows you to\nspecify a ",(0,r.kt)("inlineCode",{parentName:"a"},"gpu_vendor"))," and ",(0,r.kt)("a",{parentName:"p",href:"/api/step-decorators/batch"},(0,r.kt)("inlineCode",{parentName:"a"},"@batch")," allows you to\nspecify a ",(0,r.kt)("inlineCode",{parentName:"a"},"queue"))," targeting a compute environment containing\nspecific GPUs. For more information, see guidance for ",(0,r.kt)("a",{parentName:"p",href:"aws-batch"},"AWS Batch")," and ",(0,r.kt)("a",{parentName:"p",href:"kubernetes"},"Kubernetes"),"."),(0,r.kt)("h3",{id:"using-aws-trainium-and-inferentia"},"Using AWS Trainium and Inferentia"),(0,r.kt)("p",null,"On AWS, you can use AWS-specific hardware accelerators, Trainium and Inferentia.\nFor more details, see ",(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/blogs/machine-learning/develop-and-train-large-models-cost-efficiently-with-metaflow-and-aws-trainium/"},"a blog post outlining them in the context of Metaflow"),"."),(0,r.kt)("p",null,"When using AWS Batch, you can request the accelerators simply by defining the number\nof Trainium or Inferentia cores in ",(0,r.kt)("inlineCode",{parentName:"p"},"@batch"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"@batch(trainium=16)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("inlineCode",{parentName:"li"},"@batch(inferentia=16)"))),(0,r.kt)("p",null,"Note that Metaflow supports ",(0,r.kt)("a",{parentName:"p",href:"distributed-computing"},"distributed training")," over multiple\nTrainium instances. For detailed instructions, visit\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/metaflow-trainium/tree/main"},(0,r.kt)("inlineCode",{parentName:"a"},"metaflow-trainium")," repository"),"."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"Contact ",(0,r.kt)("a",{parentName:"p",href:"http://chat.metaflow.org"},"Metaflow Slack")," if you are interested in using Trainium\nof Inferentia with ",(0,r.kt)("inlineCode",{parentName:"p"},"@kubernetes"),".")),(0,r.kt)("h3",{id:"using-googles-tensor-processing-units-tpus"},"Using Google's Tensor Processing Units (TPUs)"),(0,r.kt)("p",null,"Contact ",(0,r.kt)("a",{parentName:"p",href:"http://chat.metaflow.org"},"Metaflow Slack")," if you are interested in using TPUs with\nMetaflow in the Google cloud."),(0,r.kt)("h2",{id:"monitoring-gpu-utilization"},"Monitoring GPU utilization"),(0,r.kt)("p",null,"To monitor GPU devices and their utilization, add ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/outerbounds/metaflow-gpu-profile"},"a custom card\n",(0,r.kt)("inlineCode",{parentName:"a"},"@gpu_profile"))," in your GPU steps."),(0,r.kt)("p",null,(0,r.kt)("img",{src:n(4443).Z,width:"720",height:"507"})))}c.isMDXComponent=!0},4443:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/gpu_profile-0c73924e0b77552f4dc46608ae188f45.png"}}]);